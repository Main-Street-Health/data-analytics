{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "import random\n",
    "import collections\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, BaggingRegressor, StackingRegressor\n",
    "from sklearn.linear_model import Ridge, Lasso, BayesianRidge, ElasticNet\n",
    "\n",
    "sys.path.append('../src')\n",
    "import cb_utils\n",
    "\n",
    "sns.set(style=\"darkgrid\")\n",
    "pd.options.display.max_columns = 500\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# configuration\n",
    "scoring_run_id = 1\n",
    "use_cache = False\n",
    "seed = random.randint(0, 100)\n",
    "test_set_pct = 0.2\n",
    "print(f'Seed: {seed}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "# 2018\n",
    "query = \"SELECT * FROM cb.vw_mab_training_data WHERE mab_id = 4;\"\n",
    "mab4 = cb_utils.sql_query_to_df(query, use_cache=use_cache)\n",
    "mab4.fillna(0, inplace=True)\n",
    "\n",
    "# 2017\n",
    "query = \"SELECT * FROM cb.vw_mab_training_data WHERE mab_id = 3;\"\n",
    "mab3 = cb_utils.sql_query_to_df(query, use_cache=use_cache)\n",
    "mab3.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mom_feature_columns = [\n",
    "#     'lob_at_id'\n",
    "#   , 'grp_at_id'\n",
    "    'lob_1_days'\n",
    "  , 'lob_2_days'\n",
    "  , 'lob_3_days'\n",
    "  , 'grp_1_days'\n",
    "  , 'grp_2_days'\n",
    "  , 'grp_3_days'\n",
    "  , 'grp_5_days'\n",
    "  , 'grp_6_days'\n",
    "  , 'grp_7_days'\n",
    "  , 'grp_8_days'\n",
    "  , 'unaligned_days'\n",
    "#   , 'is_unaligned'\n",
    "  , 'tc'\n",
    "  , 'hcbs_tc'\n",
    "  , 'icf_tc'\n",
    "  , 'ip_tc'\n",
    "  , 'rx_tc'\n",
    "  , 'ed_tc'\n",
    "  , 'snf_tc'\n",
    "  , 'out_tc'\n",
    "  , 'pro_tc'\n",
    "  , 'spfac_tc'\n",
    "  , 'amb_tc'\n",
    "  , 'hh_tc'\n",
    "  , 'hosp_tc'\n",
    "  , 'oth_tc'\n",
    "  , 'p_mm'\n",
    "  , 'mm'\n",
    "  , 'hcbs_respite_tc'\n",
    "  , 'hcbs_fam_care_stip_tc'\n",
    "  , 'hcbs_com_trans_tc'\n",
    "  , 'hcbs_educ_train_tc'\n",
    "  , 'hcbs_com_liv_fam_tc'\n",
    "  , 'hcbs_com_liv_tc'\n",
    "  , 'hcbs_attend_care_tc'\n",
    "  , 'hcbs_com_trans_waiv_tc'\n",
    "  , 'hcbs_home_meal_tc'\n",
    "  , 'hcbs_pers_care_tc'\n",
    "  , 'hcbs_ther_behav_tc'\n",
    "  , 'hcbs_unsk_respite_tc'\n",
    "  , 'hcbs_waiv_svc_tc'\n",
    "  , 'ddos'\n",
    "  , 'hcbs_ddos'\n",
    "  , 'icf_ddos'\n",
    "  , 'ip_ddos'\n",
    "  , 'rx_ddos'\n",
    "  , 'ed_ddos'\n",
    "  , 'snf_ddos'\n",
    "  , 'out_ddos'\n",
    "  , 'pro_ddos'\n",
    "  , 'spfac_ddos'\n",
    "  , 'amb_ddos'\n",
    "  , 'hh_ddos'\n",
    "  , 'hosp_ddos'\n",
    "  , 'oth_ddos'\n",
    "  , 'pcp_ddos'\n",
    "  , 'chf_ddos'\n",
    "  , 'heart_ddos'\n",
    "  , 'copd_ddos'\n",
    "  , 'pulmonar_ddos'\n",
    "  , 'cancer_ddos'\n",
    "  , 'ckd_ddos'\n",
    "  , 'esrd_ddos'\n",
    "  , 'hyperlipid_ddos'\n",
    "  , 'diab_ddos'\n",
    "  , 'alzh_ddos'\n",
    "  , 'dementia_ddos'\n",
    "  , 'stroke_ddos'\n",
    "  , 'hypertension_ddos'\n",
    "  , 'fall_ddos'\n",
    "  , 'transplant_ddos'\n",
    "  , 'liver_ddos'\n",
    "  , 'hippfract_ddos'\n",
    "  , 'depression_ddos'\n",
    "  , 'psychosis_ddos'\n",
    "  , 'drug_ddos'\n",
    "  , 'alcohol_ddos'\n",
    "  , 'paralysis_ddos'\n",
    "]\n",
    "annual_feature_columns = [\n",
    "#   , 'lvl_ft'\n",
    "#   , 'is_unaligned_ft'\n",
    "    'unaligned_mm_ft'\n",
    "  , 'is_self_directed_ft'\n",
    "  , 'is_cat0_ft'\n",
    "  , 'is_cat1_ft'\n",
    "  , 'is_cat2_ft'\n",
    "  , 'is_cat3_ft'\n",
    "  , 'is_cat4_ft'\n",
    "  , 'is_lob1_ft'\n",
    "  , 'is_lob2_ft'\n",
    "  , 'is_lob3_ft'\n",
    "  , 'is_grp1_ft'\n",
    "  , 'is_grp2_ft'\n",
    "  , 'is_grp3_ft'\n",
    "  , 'is_grp45678_ft'\n",
    "  , 'sav_pct_ft'\n",
    "  , 'raf_sav_pct_ft'\n",
    "  , 'ds_sav_pct_ft'\n",
    "  , 'ip_sav_pct_ft'\n",
    "  , 'snf_sav_pct_ft'\n",
    "  , 'icf_sav_pct_ft'\n",
    "  , 'ed_sav_pct_ft'\n",
    "  , 'hh_sav_pct_ft'\n",
    "  , 'pro_sav_pct_ft'\n",
    "  , 'out_sav_pct_ft'\n",
    "  , 'savings_ft'\n",
    "  , 'raf_savings_ft'\n",
    "  , 'ds_savings_ft'\n",
    "  , 'ip_savings_ft'\n",
    "  , 'snf_savings_ft'\n",
    "  , 'icf_savings_ft'\n",
    "  , 'ed_savings_ft'\n",
    "  , 'hh_savings_ft'\n",
    "  , 'pro_savings_ft'\n",
    "  , 'out_savings_ft'\n",
    "  , 'tc_ft'\n",
    "  , 'hcbs_atd_pcs_tc_ft'\n",
    "  , 'ip_tc_ft'\n",
    "  , 'snf_tc_ft'\n",
    "  , 'icf_tc_ft'\n",
    "  , 'ed_tc_ft'\n",
    "  , 'hh_tc_ft'\n",
    "  , 'pro_tc_ft'\n",
    "  , 'out_tc_ft'\n",
    "  , 'savings_pmpm_ft'\n",
    "  , 'raf_sav_pmpm_ft'\n",
    "  , 'ds_sav_pmpm_ft'\n",
    "  , 'ip_sav_pmpm_ft'\n",
    "  , 'snf_sav_pmpm_ft'\n",
    "  , 'icf_sav_pmpm_ft'\n",
    "  , 'ed_sav_pmpm_ft'\n",
    "  , 'hh_sav_pmpm_ft'\n",
    "  , 'pro_sav_pmpm_ft'\n",
    "  , 'out_sav_pmpm_ft'\n",
    "  , 'tc_pmpm_ft'\n",
    "  , 'hcbs_attd_pmpm_ft'\n",
    "  , 'ip_pmpm_ft'\n",
    "  , 'snf_pmpm_ft'\n",
    "  , 'icf_pmpm_ft'\n",
    "  , 'ed_pmpm_ft'\n",
    "  , 'hh_pmpm_ft'\n",
    "  , 'pro_pmpm_ft'\n",
    "  , 'out_pmpm_ft'\n",
    "  , 'mm_ft'\n",
    "\n",
    "]\n",
    "target_col = 'savings_tgt'\n",
    "lvl = '2. m'\n",
    "\n",
    "feature_columns = mom_feature_columns + annual_feature_columns\n",
    "print(f'N Potential Features: {len(feature_columns)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Features pulled from feature selection in separate notebook\n",
    "`bjp_multi_model_v4_feature_selection_chf_copd_added_in.ipynb`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# features from selection method actually performs worse than all features!\n",
    "feature_cols = ['p_mm', 'alzh_ddos', 'amb_ddos', 'amb_tc', 'cancer_ddos', 'chf_ddos', 'copd_ddos', 'ddos', 'dementia_ddos', 'depression_ddos', 'diab_ddos', 'ds_sav_pct_ft', 'ds_sav_pmpm_ft', 'ds_savings_ft', 'ed_ddos', 'ed_sav_pct_ft', 'ed_sav_pmpm_ft', 'ed_savings_ft', 'ed_tc', 'esrd_ddos', 'fall_ddos', 'grp_1_days', 'hcbs_attd_pmpm_ft', 'hcbs_attend_care_tc', 'hcbs_com_liv_fam_tc', 'hcbs_com_trans_waiv_tc', 'hcbs_ddos', 'hcbs_home_meal_tc', 'hcbs_tc', 'hcbs_unsk_respite_tc', 'heart_ddos', 'hh_ddos', 'hh_sav_pct_ft', 'hh_sav_pmpm_ft', 'hh_savings_ft', 'hh_tc', 'hh_tc_ft', 'hosp_ddos', 'hyperlipid_ddos', 'hypertension_ddos', 'icf_ddos', 'icf_sav_pct_ft', 'icf_sav_pmpm_ft', 'icf_savings_ft', 'icf_tc', 'ip_ddos', 'ip_sav_pct_ft', 'ip_sav_pmpm_ft', 'ip_savings_ft', 'is_cat3_ft', 'is_cat4_ft', 'is_grp1_ft', 'is_grp2_ft', 'is_lob3_ft', 'is_self_directed_ft', 'liver_ddos', 'mm', 'oth_ddos', 'out_ddos', 'out_sav_pct_ft', 'out_sav_pmpm_ft', 'out_savings_ft', 'out_tc', 'pcp_ddos', 'pro_ddos', 'pro_sav_pct_ft', 'pro_sav_pmpm_ft', 'pro_savings_ft', 'psychosis_ddos', 'pulmonar_ddos', 'rx_ddos', 'sav_pct_ft', 'savings_ft', 'savings_pmpm_ft', 'snf_pmpm_ft', 'snf_sav_pct_ft', 'snf_sav_pmpm_ft', 'snf_savings_ft', 'snf_tc', 'stroke_ddos', 'unaligned_mm_ft', 'ckd_ddos', 'is_cat0_ft', 'is_lob2_ft', 'mm_ft', 'snf_ddos']\n",
    "\n",
    "mom_feats = [c for c in feature_cols if c in mom_feature_columns]\n",
    "annual_feats = [c for c in feature_cols if c in annual_feature_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = mab4.loc[mab4.lvl_tgt == lvl]\n",
    "\n",
    "targets_df = df[['member_id', target_col]].groupby('member_id').first()\n",
    "\n",
    "# features_df = cb_utils.features_annual(df, mom_feature_columns)\n",
    "# pre_annual = df.query(\"period < 0\")[annual_feature_columns + ['member_id']].groupby('member_id').first()\n",
    "features_df = cb_utils.features_annual(df, mom_feats)\n",
    "pre_annual = df.query(\"period < 0\")[annual_feats + ['member_id']].groupby('member_id').first()\n",
    "\n",
    "features_df = features_df.merge(pre_annual, left_index=True, right_index=True)\n",
    "features_df.fillna(0, inplace=True)\n",
    "\n",
    "# order features and targets by member id, make sure they line up perfectly\n",
    "features_df.sort_index(inplace=True)\n",
    "targets_df.sort_index(inplace=True)\n",
    "assert sum(targets_df.index - features_df.index) == 0\n",
    "\n",
    "# train test split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check ridge vs lasso regression lift perf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lasso\n",
    "l_models = [Lasso(alpha=1.0, normalize=True) for _ in range(1000)]\n",
    "l_lifts = []\n",
    "\n",
    "for model in l_models:\n",
    "    seed = random.randint(0, 10000)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(features_df, targets_df[target_col], test_size=test_set_pct, random_state=seed)\n",
    "    model.fit(X_train, y_train)\n",
    "    preds = model.predict(X_test)\n",
    "    pred_misses, rule_misses = cb_utils.get_miss_ided(X_test, y_test, preds, verbose=False)\n",
    "    l_lifts.append(rule_misses - pred_misses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ridge\n",
    "r_models = [Ridge(alpha=1.0, normalize=True) for _ in range(1000)]\n",
    "r_lifts = []\n",
    "\n",
    "for model in r_models:\n",
    "    seed = random.randint(0, 10000)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(features_df, targets_df[target_col], test_size=test_set_pct, random_state=seed)\n",
    "    model.fit(X_train, y_train)\n",
    "    preds = model.predict(X_test)\n",
    "    pred_misses, rule_misses = cb_utils.get_miss_ided(X_test, y_test, preds, verbose=False)\n",
    "    r_lifts.append(rule_misses - pred_misses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mixed\n",
    "m_models = [Ridge(alpha=1.0, normalize=True) for _ in range(500)] + [Lasso(alpha=1.0, normalize=True) for _ in range(500)]\n",
    "m_lifts = []\n",
    "\n",
    "for model in m_models:\n",
    "    seed = random.randint(0, 10000)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(features_df, targets_df[target_col], test_size=test_set_pct, random_state=seed)\n",
    "    model.fit(X_train, y_train)\n",
    "    preds = model.predict(X_test)\n",
    "    pred_misses, rule_misses = cb_utils.get_miss_ided(X_test, y_test, preds, verbose=False)\n",
    "    m_lifts.append(rule_misses - pred_misses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# elastic net\n",
    "e_models = [ElasticNet(alpha=1.0, normalize=True) for _ in range(1000)]\n",
    "e_lifts = []\n",
    "\n",
    "for model in e_models:\n",
    "    seed = random.randint(0, 10000)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(features_df, targets_df[target_col], test_size=test_set_pct, random_state=seed)\n",
    "    model.fit(X_train, y_train)\n",
    "    preds = model.predict(X_test)\n",
    "    pred_misses, rule_misses = cb_utils.get_miss_ided(X_test, y_test, preds, verbose=False)\n",
    "    e_lifts.append(rule_misses - pred_misses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bayes\n",
    "b_models = [BayesianRidge(normalize=True) for _ in range(1000)]\n",
    "b_lifts = []\n",
    "\n",
    "for model in b_models:\n",
    "    seed = random.randint(0, 10000)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(features_df, targets_df[target_col], test_size=test_set_pct, random_state=seed)\n",
    "    model.fit(X_train, y_train)\n",
    "    preds = model.predict(X_test)\n",
    "    pred_misses, rule_misses = cb_utils.get_miss_ided(X_test, y_test, preds, verbose=False)\n",
    "    b_lifts.append(rule_misses - pred_misses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bayes lasso\n",
    "bl_models = [BayesianRidge(normalize=True) for _ in range(500)] + [Lasso(alpha=1.0, normalize=True) for _ in range(500)]\n",
    "bl_lifts = []\n",
    "\n",
    "for model in bl_models:\n",
    "    seed = random.randint(0, 10000)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(features_df, targets_df[target_col], test_size=test_set_pct, random_state=seed)\n",
    "    model.fit(X_train, y_train)\n",
    "    preds = model.predict(X_test)\n",
    "    pred_misses, rule_misses = cb_utils.get_miss_ided(X_test, y_test, preds, verbose=False)\n",
    "    bl_lifts.append(rule_misses - pred_misses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(l_lifts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(r_lifts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(m_lifts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(e_lifts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(b_lifts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(bl_lifts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test model on 2017 all features\n",
    "df = mab3.loc[mab3.lvl_tgt == lvl]\n",
    "targets_df = df[['member_id', target_col]].groupby('member_id').first()\n",
    "\n",
    "# features_df = cb_utils.features_annual(df, mom_feats)\n",
    "# pre_annual = df.query(\"period < 0\")[annual_feats + ['member_id']].groupby('member_id').first()\n",
    "features_df = cb_utils.features_annual(df, mom_feature_columns)\n",
    "pre_annual = df.query(\"period < 0\")[annual_feature_columns + ['member_id']].groupby('member_id').first()\n",
    "\n",
    "features_df = features_df.merge(pre_annual, left_index=True, right_index=True)\n",
    "features_df.fillna(0, inplace=True)\n",
    "\n",
    "# order features and targets by member id, make sure they line up perfectly\n",
    "features_df.sort_index(inplace=True)\n",
    "targets_df.sort_index(inplace=True)\n",
    "assert sum(targets_df.index - features_df.index) == 0\n",
    "\n",
    "preds = np.mean([model.predict(features_df) for model in b_models], axis=0)\n",
    "pred_misses, rule_misses = cb_utils.get_miss_ided(features_df, targets_df[target_col], preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test model on 2017 features subset\n",
    "df = mab3.loc[mab3.lvl_tgt == lvl]\n",
    "targets_df = df[['member_id', target_col]].groupby('member_id').first()\n",
    "\n",
    "features_df = cb_utils.features_annual(df, mom_feats)\n",
    "pre_annual = df.query(\"period < 0\")[annual_feats + ['member_id']].groupby('member_id').first()\n",
    "# features_df = cb_utils.features_annual(df, mom_feature_columns)\n",
    "# pre_annual = df.query(\"period < 0\")[annual_feature_columns + ['member_id']].groupby('member_id').first()\n",
    "\n",
    "features_df = features_df.merge(pre_annual, left_index=True, right_index=True)\n",
    "features_df.fillna(0, inplace=True)\n",
    "\n",
    "# order features and targets by member id, make sure they line up perfectly\n",
    "features_df.sort_index(inplace=True)\n",
    "targets_df.sort_index(inplace=True)\n",
    "assert sum(targets_df.index - features_df.index) == 0\n",
    "\n",
    "preds = np.mean([model.predict(features_df) for model in b_models], axis=0)\n",
    "pred_misses, rule_misses = cb_utils.get_miss_ided(features_df, targets_df[target_col], preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta = {'name': '4_m_savings_br_1000', 'features': list(features_df.columns), 'lvl_tgt': '2. m', 'family': 'bayes ridge regr'}\n",
    "cb_utils.publish_model(b_models, '4_m_savings_br_1000', '1000 bayes ridge regressors m target', 'brr', meta, inserted_by='bpierson')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_name = cb_utils.save_model(models, '4_m_savings_brr_1000', meta)\n",
    "# model_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_name = '3_m_savings_multi_ensemble'\n",
    "# model, meta = cb_utils.load_model(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cb_utils.create_scoring_run(mab_id=3, model_id=4, description='2017 test', inserted_by='bpierson')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cb_utils.save_scores(targets_df.assign(pred=preds), 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test on 2018"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cb_utils.create_scoring_run(mab_id=4, model_id=4, description='2018 test', inserted_by='bpierson')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = '20200805_135604_4_m_savings_br_1000'\n",
    "models, meta = cb_utils.load_model(model_name)\n",
    "feature_cols = meta['features']\n",
    "\n",
    "mom_feats = [c for c in feature_cols if c in mom_feature_columns]\n",
    "annual_feats = [c for c in feature_cols if c in annual_feature_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = mab4.loc[mab4.lvl_tgt == meta['lvl_tgt']]\n",
    "targets_df = df[['member_id', target_col]].groupby('member_id').first()\n",
    "\n",
    "features_df = cb_utils.features_annual(df, mom_feats)\n",
    "pre_annual = df.query(\"period < 0\")[annual_feats + ['member_id']].groupby('member_id').first()\n",
    "\n",
    "features_df = features_df.merge(pre_annual, left_index=True, right_index=True)\n",
    "features_df.fillna(0, inplace=True)\n",
    "\n",
    "# order features and targets by member id, make sure they line up perfectly\n",
    "features_df.sort_index(inplace=True)\n",
    "targets_df.sort_index(inplace=True)\n",
    "assert sum(targets_df.index - features_df.index) == 0\n",
    "\n",
    "preds = np.mean([model.predict(features_df) for model in models], axis=0)\n",
    "pred_misses, rule_misses = cb_utils.get_miss_ided(features_df, targets_df[target_col], preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cb_utils.save_scores(targets_df.assign(pred=preds), 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raise Exception(\"Stop here, Old code below\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
