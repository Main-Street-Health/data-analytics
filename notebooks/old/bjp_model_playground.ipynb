{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "\n",
    "sys.path.append('../src')\n",
    "import cb_utils\n",
    "\n",
    "sns.set(style=\"darkgrid\")\n",
    "pd.options.display.max_columns = 500\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# configuration\n",
    "use_cache = True\n",
    "seed = 0\n",
    "test_set_pct = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "query = \"SELECT * FROM cb.mab_cost_util WHERE mab_id = 1;\"\n",
    "data = cb_utils.sql_query_to_df(query, use_cache=use_cache)\n",
    "cats = cb_utils.sql_query_to_df(\"select * from junk.uhc_mbrs_for_model_id_2018_12_31;\", use_cache=use_cache)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_columns = [\n",
    "    '_lob_1_days',\n",
    "    '_lob_2_days',\n",
    "    '_lob_3_days',\n",
    "    '_grp_1_days',\n",
    "    '_grp_2_days',\n",
    "    '_grp_3_days',\n",
    "    '_grp_5_days',\n",
    "    '_grp_6_days',\n",
    "    '_grp_7_days',\n",
    "    '_grp_8_days',\n",
    "    '_unaligned_days',\n",
    "#     'is_unaligned',\n",
    "    'tc',\n",
    "    'hcbs_tc',\n",
    "    'icf_tc',\n",
    "    'ip_tc',\n",
    "    'rx_tc',\n",
    "    'ed_tc',\n",
    "    'snf_tc',\n",
    "    'out_tc',\n",
    "    'pro_tc',\n",
    "    'spfac_tc',\n",
    "    'amb_tc',\n",
    "    'hh_tc',\n",
    "    'hosp_tc',\n",
    "    'oth_tc',\n",
    "    'p_mm',\n",
    "    'mm',\n",
    "    'hcbs_respite_tc',\n",
    "    'hcbs_fam_care_stip_tc',\n",
    "    'hcbs_com_trans_tc',\n",
    "    'hcbs_educ_train_tc',\n",
    "    'hcbs_com_liv_fam_tc',\n",
    "    'hcbs_com_liv_tc',\n",
    "    'hcbs_attend_care_tc',\n",
    "    'hcbs_com_trans_waiv_tc',\n",
    "    'hcbs_home_meal_tc',\n",
    "    'hcbs_pers_care_tc',\n",
    "#     'hcbs_ther_behav_tc',\n",
    "    'hcbs_unsk_respite_tc',\n",
    "    'hcbs_waiv_svc_tc',\n",
    "    'ddos',\n",
    "    'hcbs_ddos',\n",
    "    'icf_ddos',\n",
    "    'ip_ddos',\n",
    "    'rx_ddos',\n",
    "    'ed_ddos',\n",
    "    'snf_ddos',\n",
    "    'out_ddos',\n",
    "    'pro_ddos',\n",
    "    'spfac_ddos',\n",
    "    'amb_ddos',\n",
    "    'hh_ddos',\n",
    "    'hosp_ddos',\n",
    "    'oth_ddos',\n",
    "    'pcp_ddos',\n",
    "    'pulmonar_ddos',\n",
    "    'cancer_ddos',\n",
    "    'ckd_ddos',\n",
    "    'esrd_ddos',\n",
    "    'hyperlipid_ddos',\n",
    "    'diab_ddos',\n",
    "    'alzh_ddos',\n",
    "    'dementia_ddos',\n",
    "    'stroke_ddos',\n",
    "    'hypertension_ddos',\n",
    "    'fall_ddos',\n",
    "    'transplant_ddos',\n",
    "    'liver_ddos',\n",
    "    'hippfract_ddos',\n",
    "    'depression_ddos',\n",
    "    'psychosis_ddos',\n",
    "    'drug_ddos',\n",
    "    'alcohol_ddos',\n",
    "    'paralysis_ddos'\n",
    "]\n",
    "len(feature_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try agg features at year and half year level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fully broken out month over month features\n",
    "def features_mom(data, feature_columns):\n",
    "    print('building month over month features')\n",
    "    pre = data.query(\"period < 0\")\n",
    "    return pre.pivot(index='member_id', columns='period', values=feature_columns)\n",
    "features_mom.name = 'MOM'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# agg semi yearly_features\n",
    "def features_semi_annual(data, feature_columns):\n",
    "    print('building semi annual features')\n",
    "    pre = data.query(\"period < 0\")\n",
    "    h1 = pre.query('period < -6').groupby('member_id')\n",
    "    h2 = pre.query('period >= -6').groupby('member_id')\n",
    "\n",
    "    h1 = h1.sum()\n",
    "    h2 = h2.sum()\n",
    "\n",
    "    features_h1 = np.divide(h1[feature_columns],  h1[['p_mm']])\n",
    "    features_h2 = np.divide(h2[feature_columns],  h2[['p_mm']])\n",
    "    return features_h2.merge(features_h1, left_index=True, right_index=True, suffixes=('_h2', '_h1'))\n",
    "features_semi_annual.name = 'Semi Annual'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# agg yearly_features\n",
    "def features_annual(data, feature_columns):\n",
    "    print('building annual features')\n",
    "    pre = data.query(\"period < 0\").groupby('member_id')\n",
    "    pre_sums = pre.sum()\n",
    "    return np.divide(pre_sums[feature_columns],  pre_sums[['p_mm']])\n",
    "features_annual.name = 'Annual'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_targets(cats, level):\n",
    "    print(f'building {level} targets')\n",
    "    return cats.query('lvl == @level')[['member_id', 'savings_tc', 'cat_pre']].set_index('member_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_train_test_set(data, cats, feature_func, targets, feature_columns=feature_columns):\n",
    "    features = feature_func(data, feature_columns)\n",
    "    feature_targets = features.merge(targets, left_index=True, right_index=True)\n",
    "    feature_targets = feature_targets.fillna(0)\n",
    "    \n",
    "    x_cols = [c for c in feature_targets.columns if c != 'savings_tc']\n",
    "    X = feature_targets[x_cols]\n",
    "    \n",
    "#     display(feature_targets.columns)\n",
    "    y = feature_targets.savings_tc\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_set_pct, random_state=seed)\n",
    "    return X_train, X_test, y_train, y_test, x_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train and test some tree models\n",
    "def train_and_evaluate(regr, X_train=None, X_test=None, y_train=None, y_test=None, verbose=True, plot_result=True, plot_title=\"\"):\n",
    "    regr.fit(X_train, y_train)\n",
    "    preds = regr.predict(X_test)\n",
    "    error = np.abs(y_test - preds)\n",
    "    mean_hrs_error = error.mean()\n",
    "    median_hrs_error = error.median()\n",
    "    r2_score = regr.score(X_test, y_test)\n",
    "\n",
    "\n",
    "    if verbose:\n",
    "        print(f'R^2 Score: {r2_score}')\n",
    "        print(f'Mean absolute $ error: {mean_hrs_error}')\n",
    "        print(f'Median absolute $ error: {median_hrs_error}')\n",
    "        print('Feature Importance')\n",
    "        for imp, feat in sorted([(b, a) for a, b in zip(feature_columns, regr.feature_importances_)], reverse=True):\n",
    "            if imp > 0.001:\n",
    "                print('%0.3f: %s' % (imp, feat))\n",
    "\n",
    "    if plot_result:\n",
    "        fig, axes = plt.subplots(nrows=2, figsize=(20,20))\n",
    "        ax = axes[0]\n",
    "        ax.scatter(preds, y_test)\n",
    "        ax.set_xlabel('preds')\n",
    "        ax.set_ylabel('actual');\n",
    "        ax.set_title(f'{plot_title}: Predicted vs actual savings')\n",
    "\n",
    "        ax = axes[1]\n",
    "        ax.hist(error)\n",
    "        ax.set_title('Histogram of absolute error in TC savings')\n",
    "        plt.show()\n",
    "        \n",
    "    return preds\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search = True\n",
    "if grid_search:\n",
    "    combos = [(f, lv) for f in (features_annual, features_semi_annual, features_mom) for lv in ('1. h', '2. m', '3. l')]\n",
    "#     combos = [(f, lv) for f in (features_annual, features_semi_annual, features_mom) for lv in ('2. m',)]\n",
    "    for f, lv in combos:\n",
    "        X_train, X_test, y_train, y_test, _ = build_train_test_set(data, cats, f, build_targets(cats, lv))\n",
    "        gb = GradientBoostingRegressor(random_state=seed)\n",
    "        gb_preds = train_and_evaluate(gb, X_train=X_train, X_test=X_test, y_train=y_train, y_test=y_test, verbose=True, plot_result=True, plot_title=f'Level: {lv} - Features: {f.name}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rf = RandomForestRegressor(random_state=seed)\n",
    "# rf_preds = train_and_evaluate(rf, verbose=False, plot_result=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gb = GradientBoostingRegressor(random_state=seed)\n",
    "# gb_preds = train_and_evaluate(gb, verbose=False, plot_result=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test, x_cols = build_train_test_set(data, cats, features_semi_annual, build_targets(cats, '3. l'))\n",
    "gb = GradientBoostingRegressor(random_state=seed)\n",
    "gb_preds = train_and_evaluate(gb, X_train=X_train, X_test=X_test, y_train=y_train, y_test=y_test, verbose=False, plot_result=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = cb_utils.save_model(gb, 'test_saving_xgb', {'name': 'test', 'features': list(x_cols.values) })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, meta = cb_utils.load_model(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = features_semi_annual(data, feature_columns)\n",
    "features = features.merge(build_targets(cats, '3. l'), left_index=True, right_index=True) # for now targets has a feature (pre cat)\n",
    "X = features[meta['features']].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model.predict(X)\n",
    "results = X.assign(pred=preds).sort_values('pred', ascending=False)[['pred']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "post_mem_grps = data.query('period > 0').groupby('member_id').sum()\n",
    "final = results.merge(post_mem_grps, left_index=True, right_index=True)\n",
    "final.head()\n",
    "# post = post_mem_grps "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_500 = final.iloc[:500].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cb_utils.save_scores(final)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
