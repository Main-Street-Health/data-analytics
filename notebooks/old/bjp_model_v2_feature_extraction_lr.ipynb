{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "import random\n",
    "import collections\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn import preprocessing\n",
    "\n",
    "sys.path.append('../src')\n",
    "import cb_utils\n",
    "\n",
    "sns.set(style=\"darkgrid\")\n",
    "pd.options.display.max_columns = 500\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# configuration\n",
    "scoring_run_id = 1\n",
    "use_cache = True\n",
    "seed = random.randint(0, 100)\n",
    "test_set_pct = 0.2\n",
    "print(f'Seed: {seed}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "query = \"SELECT * FROM cb.vw_mab_training_data WHERE mab_id = 1;\"\n",
    "data = cb_utils.sql_query_to_df(query, use_cache=use_cache)\n",
    "data.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mom_feature_columns = [\n",
    "    'lob_1_days'\n",
    "  , 'lob_2_days'\n",
    "  , 'lob_3_days'\n",
    "  , 'grp_1_days'\n",
    "  , 'grp_2_days'\n",
    "  , 'grp_3_days'\n",
    "  , 'grp_5_days'\n",
    "  , 'grp_6_days'\n",
    "  , 'grp_7_days'\n",
    "  , 'grp_8_days'\n",
    "  , 'unaligned_days'\n",
    "#   , 'is_unaligned'\n",
    "  , 'tc'\n",
    "  , 'hcbs_tc'\n",
    "  , 'icf_tc'\n",
    "  , 'ip_tc'\n",
    "  , 'rx_tc'\n",
    "  , 'ed_tc'\n",
    "  , 'snf_tc'\n",
    "  , 'out_tc'\n",
    "  , 'pro_tc'\n",
    "  , 'spfac_tc'\n",
    "  , 'amb_tc'\n",
    "  , 'hh_tc'\n",
    "  , 'hosp_tc'\n",
    "  , 'oth_tc'\n",
    "  , 'p_mm'\n",
    "  , 'mm'\n",
    "  , 'hcbs_respite_tc'\n",
    "  , 'hcbs_fam_care_stip_tc'\n",
    "  , 'hcbs_com_trans_tc'\n",
    "  , 'hcbs_educ_train_tc'\n",
    "  , 'hcbs_com_liv_fam_tc'\n",
    "  , 'hcbs_com_liv_tc'\n",
    "  , 'hcbs_attend_care_tc'\n",
    "  , 'hcbs_com_trans_waiv_tc'\n",
    "  , 'hcbs_home_meal_tc'\n",
    "  , 'hcbs_pers_care_tc'\n",
    "  , 'hcbs_ther_behav_tc'\n",
    "  , 'hcbs_unsk_respite_tc'\n",
    "  , 'hcbs_waiv_svc_tc'\n",
    "  , 'ddos'\n",
    "  , 'hcbs_ddos'\n",
    "  , 'icf_ddos'\n",
    "  , 'ip_ddos'\n",
    "  , 'rx_ddos'\n",
    "  , 'ed_ddos'\n",
    "  , 'snf_ddos'\n",
    "  , 'out_ddos'\n",
    "  , 'pro_ddos'\n",
    "  , 'spfac_ddos'\n",
    "  , 'amb_ddos'\n",
    "  , 'hh_ddos'\n",
    "  , 'hosp_ddos'\n",
    "  , 'oth_ddos'\n",
    "  , 'pcp_ddos'\n",
    "  , 'pulmonar_ddos'\n",
    "  , 'cancer_ddos'\n",
    "  , 'ckd_ddos'\n",
    "  , 'esrd_ddos'\n",
    "  , 'hyperlipid_ddos'\n",
    "  , 'diab_ddos'\n",
    "  , 'alzh_ddos'\n",
    "  , 'dementia_ddos'\n",
    "  , 'stroke_ddos'\n",
    "  , 'hypertension_ddos'\n",
    "  , 'fall_ddos'\n",
    "  , 'transplant_ddos'\n",
    "  , 'liver_ddos'\n",
    "  , 'hippfract_ddos'\n",
    "  , 'depression_ddos'\n",
    "  , 'psychosis_ddos'\n",
    "  , 'drug_ddos'\n",
    "  , 'alcohol_ddos'\n",
    "  , 'paralysis_ddos'\n",
    "]\n",
    "annual_feature_columns = [\n",
    "#   , 'lvl_ft'\n",
    "#   , 'is_unaligned_ft'\n",
    "    'unaligned_mm_ft'\n",
    "  , 'is_self_directed_ft'\n",
    "  , 'is_cat0_ft'\n",
    "  , 'is_cat1_ft'\n",
    "  , 'is_cat2_ft'\n",
    "  , 'is_cat3_ft'\n",
    "  , 'is_cat4_ft'\n",
    "  , 'is_lob1_ft'\n",
    "  , 'is_lob2_ft'\n",
    "  , 'is_lob3_ft'\n",
    "  , 'is_grp1_ft'\n",
    "  , 'is_grp2_ft'\n",
    "  , 'is_grp3_ft'\n",
    "  , 'is_grp45678_ft'\n",
    "  , 'sav_pct_ft'\n",
    "  , 'raf_sav_pct_ft'\n",
    "  , 'ds_sav_pct_ft'\n",
    "  , 'ip_sav_pct_ft'\n",
    "  , 'snf_sav_pct_ft'\n",
    "  , 'icf_sav_pct_ft'\n",
    "  , 'ed_sav_pct_ft'\n",
    "  , 'hh_sav_pct_ft'\n",
    "  , 'pro_sav_pct_ft'\n",
    "  , 'out_sav_pct_ft'\n",
    "  , 'savings_ft'\n",
    "  , 'raf_savings_ft'\n",
    "  , 'ds_savings_ft'\n",
    "  , 'ip_savings_ft'\n",
    "  , 'snf_savings_ft'\n",
    "  , 'icf_savings_ft'\n",
    "  , 'ed_savings_ft'\n",
    "  , 'hh_savings_ft'\n",
    "  , 'pro_savings_ft'\n",
    "  , 'out_savings_ft'\n",
    "  , 'tc_ft'\n",
    "  , 'hcbs_atd_pcs_tc_ft'\n",
    "  , 'ip_tc_ft'\n",
    "  , 'snf_tc_ft'\n",
    "  , 'icf_tc_ft'\n",
    "  , 'ed_tc_ft'\n",
    "  , 'hh_tc_ft'\n",
    "  , 'pro_tc_ft'\n",
    "  , 'out_tc_ft'\n",
    "  , 'savings_pmpm_ft' # start pmpms\n",
    "  , 'raf_sav_pmpm_ft'\n",
    "  , 'ds_sav_pmpm_ft'\n",
    "  , 'ip_sav_pmpm_ft'\n",
    "  , 'snf_sav_pmpm_ft'\n",
    "  , 'icf_sav_pmpm_ft'\n",
    "  , 'ed_sav_pmpm_ft'\n",
    "  , 'hh_sav_pmpm_ft'\n",
    "  , 'pro_sav_pmpm_ft'\n",
    "  , 'out_sav_pmpm_ft'\n",
    "  , 'tc_pmpm_ft'\n",
    "  , 'hcbs_attd_pmpm_ft'\n",
    "  , 'ip_pmpm_ft'\n",
    "  , 'snf_pmpm_ft'\n",
    "  , 'icf_pmpm_ft'\n",
    "  , 'ed_pmpm_ft'\n",
    "  , 'hh_pmpm_ft'\n",
    "  , 'pro_pmpm_ft'\n",
    "  , 'out_pmpm_ft'\n",
    "  , 'mm_ft'\n",
    "  , 'age'\n",
    "  , 'is_male'\n",
    "]\n",
    "target_col = 'savings_tgt'\n",
    "# target_col = 'savings_pmpm_tgt'\n",
    "\n",
    "feature_columns = mom_feature_columns + annual_feature_columns\n",
    "len(feature_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try agg features at year and half year level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fully broken out month over month features\n",
    "def features_mom(df, cols):\n",
    "#     print('building month over month features')\n",
    "    df = df.fillna(0)\n",
    "    pre = df.query(\"period < 0\")\n",
    "    pre= pre.pivot(index='member_id', columns='period', values=cols)\n",
    "    pre.columns = [f'{period}-{name}' for (name, period) in pre.columns]\n",
    "    return pre.fillna(0)\n",
    "features_mom.name = 'MOM'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# agg semi yearly_features\n",
    "def features_semi_annual(df, cols):\n",
    "#     print('building semi annual features')\n",
    "    df = df.fillna(0)\n",
    "    pre = df.query(\"period < 0\")\n",
    "    h1 = pre.query('period < -6').groupby('member_id')\n",
    "    h2 = pre.query('period >= -6').groupby('member_id')\n",
    "\n",
    "    h1 = h1[cols].sum()\n",
    "    h2 = h2[cols].sum()\n",
    "\n",
    "    features_h1 = np.divide(h1[cols],  h1[['p_mm']])\n",
    "    features_h2 = np.divide(h2[cols],  h2[['p_mm']])\n",
    "    res = features_h2.merge(features_h1, left_index=True, right_index=True, suffixes=('_h2', '_h1'))\n",
    "    return res.fillna(0)\n",
    "features_semi_annual.name = 'Semi Annual'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# agg yearly_features\n",
    "def features_annual(df, cols):\n",
    "#     print('building annual features')\n",
    "    df = df.fillna(0)\n",
    "    pre = df.query(\"period < 0\").groupby('member_id')\n",
    "    pre_sums = pre[cols].sum()\n",
    "    res = np.divide(pre_sums[cols],  pre_sums[['p_mm']])\n",
    "    return res.fillna(0)\n",
    "features_annual.name = 'Annual'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_feature_importance(regr, cols, max_cols=20):\n",
    "    print('Feature Importance')\n",
    "    i = 0\n",
    "    for imp, feat in sorted([(b, a) for a, b in zip(cols, regr.feature_importances_)], reverse=True):\n",
    "        if imp > 0.001:\n",
    "            print('%0.3f: %s' % (imp, feat))\n",
    "            i += 1\n",
    "        if i > max_cols:\n",
    "            break\n",
    "            \n",
    "def print_coef_importance(regr, cols, max_cols=20):\n",
    "    print('Feature Importance')\n",
    "    i = 0\n",
    "    for imp, feat in sorted([(b, a) for a, b in zip(cols, regr.coef_)], reverse=True):\n",
    "        if imp > 0.001:\n",
    "            print('%0.3f: %s' % (imp, feat))\n",
    "            i += 1\n",
    "        if i > max_cols:\n",
    "            break\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_miss_ided(X_test, y_test, preds, verbose=True):\n",
    "    id_pop_size = 100 # test split is 20%, 20% of 500 == 100\n",
    "    test_df = X_test.assign(target=y_test, pred=preds)\n",
    "    \n",
    "    pre_rule_id = test_df.sort_values('savings_ft', ascending=False).iloc[:id_pop_size]\n",
    "    perf_id = test_df.sort_values('target', ascending=False).iloc[:id_pop_size]\n",
    "    pred_id = test_df.sort_values('pred', ascending=False).iloc[:id_pop_size]\n",
    "    \n",
    "    pred_misses = perf_id.index.difference(pred_id.index).shape[0]\n",
    "    rule_misses = perf_id.index.difference(pre_rule_id.index).shape[0]\n",
    "    \n",
    "    if verbose:\n",
    "        print(f'Miss IDed: {pred_misses * 100.0 / id_pop_size}%')\n",
    "        print(f'Rule Miss IDed: {rule_misses * 100.0 / id_pop_size}%')\n",
    "    return pred_misses, rule_misses "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run some feature selection\n",
    "Recursively runs cross validation and gets rid of features that don't have high feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lvl = '1. h'\n",
    "df = data.loc[data.lvl_tgt == lvl]\n",
    "\n",
    "targets_df = df[['member_id', target_col]].groupby('member_id').first()\n",
    "\n",
    "features_df = features_annual(df, mom_feature_columns)\n",
    "pre_annual = df.query(\"period < 0\")[annual_feature_columns + ['member_id']].groupby('member_id').first()\n",
    "\n",
    "features_df = features_df.merge(pre_annual, left_index=True, right_index=True)\n",
    "features_df.fillna(0, inplace=True)\n",
    "\n",
    "# order features and targets by member id, make sure they line up perfectly\n",
    "features_df.sort_index(inplace=True)\n",
    "targets_df.sort_index(inplace=True)\n",
    "assert sum(targets_df.index - features_df.index) == 0\n",
    "\n",
    "# train test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(features_df, targets_df[target_col], test_size=test_set_pct, random_state=seed)\n",
    "\n",
    "transformer = preprocessing.RobustScaler().fit(X_train)\n",
    "X_train = transformer.transform(X_train)\n",
    "X_test = transformer.transform(X_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import RFECV\n",
    "\n",
    "lvl = '1. h'\n",
    "df = data.loc[data.lvl_tgt == lvl]\n",
    "\n",
    "targets_df = df[['member_id', target_col]].groupby('member_id').first()\n",
    "\n",
    "features_df = features_annual(df, mom_feature_columns)\n",
    "pre_annual = df.query(\"period < 0\")[annual_feature_columns + ['member_id']].groupby('member_id').first()\n",
    "\n",
    "features_df = features_df.merge(pre_annual, left_index=True, right_index=True)\n",
    "features_df.fillna(0, inplace=True)\n",
    "\n",
    "# order features and targets by member id, make sure they line up perfectly\n",
    "features_df.sort_index(inplace=True)\n",
    "targets_df.sort_index(inplace=True)\n",
    "assert sum(targets_df.index - features_df.index) == 0\n",
    "\n",
    "# train test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(features_df, targets_df[target_col], test_size=test_set_pct, random_state=seed)\n",
    "\n",
    "estimators = [\n",
    "    ('xgb', GradientBoostingRegressor(random_state=seed)),\n",
    "    ('xgb max depth 1', GradientBoostingRegressor(random_state=seed, max_depth=1)),\n",
    "    ('ridge', Ridge(alpha=1.0, normalize=True)),\n",
    "    ('rf', RandomForestRegressor(random_state=seed)),\n",
    "]\n",
    "selectors = []\n",
    "cnt = collections.Counter()\n",
    "\n",
    "for name, estimator in estimators:\n",
    "    print(name)\n",
    "    selector = RFECV(estimator, step=1, cv=5, n_jobs=os.cpu_count())\n",
    "    selector = selector.fit(X_train, y_train)\n",
    "    selected_features = features_df.columns[selector.support_]\n",
    "    selectors.append((name, selector))\n",
    "    \n",
    "    for rank, feat in sorted([(b, a) for a, b in zip(features_df.columns, selector.ranking_)]):\n",
    "        print(f'{rank}: {feat}')\n",
    "        if rank == 1:\n",
    "            cnt[feat] += 1\n",
    "    \n",
    "    plt.figure()\n",
    "    plt.xlabel(\"Number of features selected\")\n",
    "    plt.ylabel(\"Cross validation score (nb of correct classifications)\")\n",
    "    plt.plot(range(1, len(selector.grid_scores_) + 1), selector.grid_scores_)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # of times features appear as #1 rank\n",
    "cnt.most_common(200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(4, 1, -1):\n",
    "    feature_cols = [c for c, v in cnt.items() if v >= i]\n",
    "    mom_feats = [c for c in feature_cols if c in mom_feature_columns] + ['p_mm']\n",
    "    annual_feats = [c for c in feature_cols if c in annual_feature_columns]\n",
    "    print(i, ', '.join(feature_cols))\n",
    "\n",
    "#     lvl = '2. m'\n",
    "    lvl = '1. h'\n",
    "    df = data.loc[data.lvl_tgt == lvl]\n",
    "\n",
    "    targets_df = df[['member_id', target_col]].groupby('member_id').first()\n",
    "\n",
    "    features_df = features_annual(df, mom_feats)\n",
    "    pre_annual = df.query(\"period < 0\")[annual_feats + ['member_id']].groupby('member_id').first()\n",
    "\n",
    "\n",
    "    features_df = features_df.merge(pre_annual, left_index=True, right_index=True)\n",
    "    features_df.fillna(0, inplace=True)\n",
    "\n",
    "\n",
    "    # order features and targets by member id, make sure they line up perfectly\n",
    "    features_df.sort_index(inplace=True)\n",
    "    targets_df.sort_index(inplace=True)\n",
    "    assert sum(targets_df.index - features_df.index) == 0\n",
    "\n",
    "    # train test split\n",
    "    # target_col = 'savings_tgt'\n",
    "    seed = random.randint(0, 1000)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(features_df, targets_df[target_col], test_size=test_set_pct, random_state=seed)\n",
    "\n",
    "    gb = Ridge(alpha=1.0, normalize=True)\n",
    "    #     gb = GradientBoostingRegressor(random_state=seed, max_depth=2)\n",
    "    #     gb = RandomForestRegressor(random_state=seed)\n",
    "\n",
    "    gb.fit(X_train, y_train)\n",
    "    verbose = True\n",
    "    preds = gb.predict(X_test)\n",
    "    r2_score = gb.score(X_test, y_test)\n",
    "    error = np.abs(y_test - preds)\n",
    "    mean_hrs_error = error.mean()\n",
    "    median_hrs_error = error.median()\n",
    "\n",
    "\n",
    "    print(f'R^2 Score: {r2_score}')\n",
    "    print(f'Mean absolute $ error: {mean_hrs_error}')\n",
    "    print(f'Median absolute $ error: {median_hrs_error}')\n",
    "    get_miss_ided(X_test, y_test, preds)\n",
    "#     print_feature_importance(gb, features_df.columns) # tree reg\n",
    "    print_coef_importance(gb, features_df.columns) # linear reg\n",
    "    if verbose:\n",
    "        fig, ax = plt.subplots(nrows=1, figsize=(20,10))\n",
    "        ax.scatter(preds, y_test)\n",
    "        ax.set_xlabel('preds')\n",
    "        ax.set_ylabel('actual');\n",
    "        ax.set_title(f'Predicted vs actual savings')\n",
    "        ax.set_xlim(0, 10000)\n",
    "        ax.set_ylim(0, 10000)\n",
    "#         ax.set_xscale('log')\n",
    "#         ax.set_yscale('log')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df.savings_tgt.describe())\n",
    "df.savings_tgt.hist(bins=[a for a in range(0, 10000, 500)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train 2018\n",
    "# bagging regressor, didn't work so hot\n",
    "# missed_advantage = []\n",
    "# models = []\n",
    "\n",
    "from sklearn.ensemble import BaggingRegressor\n",
    "\n",
    "# for i in range(10):\n",
    "feature_cols = [c for c, v in cnt.items() if v >= 3]\n",
    "mom_feats = [c for c in feature_cols if c in mom_feature_columns]# + ['p_mm']\n",
    "annual_feats = [c for c in feature_cols if c in annual_feature_columns]\n",
    "# print(i, ', '.join(feature_cols))\n",
    "\n",
    "#     lvl = '2. m'\n",
    "lvl = '1. h'\n",
    "df = data.loc[data.lvl_tgt == lvl]\n",
    "\n",
    "targets_df = df[['member_id', target_col]].groupby('member_id').first()\n",
    "\n",
    "features_df = features_annual(df, mom_feats)\n",
    "pre_annual = df.query(\"period < 0\")[annual_feats + ['member_id']].groupby('member_id').first()\n",
    "\n",
    "\n",
    "features_df = features_df.merge(pre_annual, left_index=True, right_index=True)\n",
    "features_df.fillna(0, inplace=True)\n",
    "\n",
    "\n",
    "# order features and targets by member id, make sure they line up perfectly\n",
    "features_df.sort_index(inplace=True)\n",
    "targets_df.sort_index(inplace=True)\n",
    "assert sum(targets_df.index - features_df.index) == 0\n",
    "\n",
    "# train test split\n",
    "# target_col = 'savings_tgt'\n",
    "seed = random.randint(0, 1000)\n",
    "print(f'seed: {seed}')\n",
    "X_train, X_test, y_train, y_test = train_test_split(features_df, targets_df[target_col], test_size=test_set_pct, random_state=seed)\n",
    "\n",
    "# gb = Ridge(alpha=1.0, normalize=True)\n",
    "gb = BaggingRegressor(base_estimator=Ridge(alpha=1.0, normalize=True), n_estimators=1000)\n",
    "#     gb = GradientBoostingRegressor(random_state=seed, max_depth=2)\n",
    "#     gb = RandomForestRegressor(random_state=seed)\n",
    "\n",
    "gb.fit(X_train, y_train)\n",
    "verbose = True\n",
    "preds = gb.predict(X_test)\n",
    "r2_score = gb.score(X_test, y_test)\n",
    "error = np.abs(y_test - preds)\n",
    "mean_hrs_error = error.mean()\n",
    "median_hrs_error = error.median()\n",
    "\n",
    "\n",
    "print(f'R^2 Score: {r2_score}')\n",
    "print(f'Mean absolute $ error: {mean_hrs_error}')\n",
    "print(f'Median absolute $ error: {median_hrs_error}')\n",
    "pred_misses, rule_misses = get_miss_ided(X_test, y_test, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train 2018 - manual avg\n",
    "# missed_advantage = []\n",
    "models = []\n",
    "lifts = []\n",
    "\n",
    "feature_cols = [c for c, v in cnt.items() if v >= 3]\n",
    "mom_feats = [c for c in feature_cols if c in mom_feature_columns]# + ['p_mm']\n",
    "annual_feats = [c for c in feature_cols if c in annual_feature_columns]\n",
    "# print(i, ', '.join(feature_cols))\n",
    "\n",
    "#     lvl = '2. m'\n",
    "lvl = '1. h'\n",
    "df = data.loc[data.lvl_tgt == lvl]\n",
    "\n",
    "targets_df = df[['member_id', target_col]].groupby('member_id').first()\n",
    "\n",
    "features_df = features_annual(df, mom_feats)\n",
    "pre_annual = df.query(\"period < 0\")[annual_feats + ['member_id']].groupby('member_id').first()\n",
    "\n",
    "\n",
    "features_df = features_df.merge(pre_annual, left_index=True, right_index=True)\n",
    "features_df.fillna(0, inplace=True)\n",
    "\n",
    "\n",
    "# order features and targets by member id, make sure they line up perfectly\n",
    "features_df.sort_index(inplace=True)\n",
    "targets_df.sort_index(inplace=True)\n",
    "assert sum(targets_df.index - features_df.index) == 0\n",
    "\n",
    "for i in range(1000):\n",
    "\n",
    "    # train test split\n",
    "    # target_col = 'savings_tgt'\n",
    "    seed = random.randint(0, 1000)\n",
    "#     print(f'seed: {seed}')\n",
    "    X_train, X_test, y_train, y_test = train_test_split(features_df, targets_df[target_col], test_size=test_set_pct, random_state=seed)\n",
    "    transformer = preprocessing.RobustScaler().fit(X_train)\n",
    "    X_train = transformer.transform(X_train)\n",
    "    X_test = transformer.transform(X_test)\n",
    "\n",
    "    gb = Ridge(alpha=1.0, normalize=True)\n",
    "#     gb = BaggingRegressor(base_estimator=Ridge(alpha=1.0, normalize=True), n_estimators=1000)\n",
    "    #     gb = GradientBoostingRegressor(random_state=seed, max_depth=2)\n",
    "    #     gb = RandomForestRegressor(random_state=seed)\n",
    "\n",
    "    gb.fit(X_train, y_train)\n",
    "    models.append(gb)\n",
    "    preds = gb.predict(X_test)\n",
    "    pred_misses, rule_misses = get_miss_ided(X_test, y_test, preds, verbose=False)\n",
    "    lifts.append(rule_misses - pred_misses)\n",
    "\n",
    "\n",
    "#     verbose = True\n",
    "#     r2_score = gb.score(X_test, y_test)\n",
    "#     error = np.abs(y_test - preds)\n",
    "#     mean_hrs_error = error.mean()\n",
    "#     median_hrs_error = error.median()\n",
    "\n",
    "\n",
    "#     print(f'R^2 Score: {r2_score}')\n",
    "#     print(f'Mean absolute $ error: {mean_hrs_error}')\n",
    "#     print(f'Median absolute $ error: {median_hrs_error}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_name = cb_utils.save_model(models, '2_h_savings_lr_1000_bag', {'name': '2_h_savings_lr_1000_bag', 'features': list(features_df.columns)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = '20200802_172434_2_h_savings_lr_10_bag'\n",
    "model, meta = cb_utils.load_model(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta['features']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"SELECT * FROM cb.vw_mab_training_data WHERE mab_id = 2;\"\n",
    "mab2 = cb_utils.sql_query_to_df(query, use_cache=use_cache)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_cols = meta['features']\n",
    "\n",
    "mom_feats = [c for c in feature_cols if c in mom_feature_columns] \n",
    "annual_feats = [c for c in feature_cols if c in annual_feature_columns]\n",
    "\n",
    "lvl = '1. h'\n",
    "df = mab2.loc[data.lvl_tgt == lvl]\n",
    "\n",
    "targets_df = df[['member_id', target_col]].groupby('member_id').first()\n",
    "\n",
    "features_df = features_annual(df, mom_feats)\n",
    "pre_annual = df.query(\"period < 0\")[annual_feats + ['member_id']].groupby('member_id').first()\n",
    "\n",
    "\n",
    "features_df = features_df.merge(pre_annual, left_index=True, right_index=True)\n",
    "features_df.fillna(0, inplace=True)\n",
    "\n",
    "\n",
    "# order features and targets by member id, make sure they line up perfectly\n",
    "features_df.sort_index(inplace=True)\n",
    "targets_df.sort_index(inplace=True)\n",
    "assert sum(targets_df.index - features_df.index) == 0\n",
    "\n",
    "# train test split\n",
    "# target_col = 'savings_tgt'\n",
    "seed = random.randint(0, 1000)\n",
    "print(f'seed: {seed}')\n",
    "# X_train, X_test, y_train, y_test = train_test_split(features_df, targets_df[target_col], test_size=test_set_pct, random_state=seed)\n",
    "\n",
    "# gb = Ridge(alpha=1.0, normalize=True)\n",
    "# gb = BaggingRegressor(base_estimator=Ridge(alpha=1.0, normalize=True), n_estimators=10, random_state=0)\n",
    "#     gb = GradientBoostingRegressor(random_state=seed, max_depth=2)\n",
    "#     gb = RandomForestRegressor(random_state=seed)\n",
    "scores = [model.predict(features_df) for model in models]\n",
    "preds = np.mean(scores, axis=0)\n",
    "# gb = model\n",
    "\n",
    "# r2_score = gb.score(features_df, targets_df[target_col])\n",
    "# preds = gb.predict(features_df)\n",
    "error = np.abs(targets_df[target_col] - preds)\n",
    "mean_hrs_error = error.mean()\n",
    "median_hrs_error = error.median()\n",
    "\n",
    "\n",
    "# print(f'R^2 Score: {r2_score}')\n",
    "print(f'Mean absolute $ error: {mean_hrs_error}')\n",
    "print(f'Median absolute $ error: {median_hrs_error}')\n",
    "pred_misses, rule_misses = get_miss_ided(features_df, targets_df[target_col], preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = features_df.assign(pred=preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cb_utils.save_scores(result, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raise Exception(\"Stop here, Old code below\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
