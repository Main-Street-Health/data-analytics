{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "\n",
    "sys.path.append('../src')\n",
    "import cb_utils\n",
    "\n",
    "sns.set(style=\"darkgrid\")\n",
    "pd.options.display.max_columns = 500\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# configuration\n",
    "scoring_run_id = 1\n",
    "use_cache = True\n",
    "seed = 0\n",
    "test_set_pct = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "query = \"SELECT * FROM cb.vw_mab_training_data WHERE mab_id = 5;\"\n",
    "data = cb_utils.sql_query_to_df(query, use_cache=use_cache)\n",
    "data.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mom_feature_columns = [\n",
    "    'lob_1_days'\n",
    "  , 'lob_2_days'\n",
    "  , 'lob_3_days'\n",
    "  , 'grp_1_days'\n",
    "  , 'grp_2_days'\n",
    "  , 'grp_3_days'\n",
    "  , 'grp_5_days'\n",
    "  , 'grp_6_days'\n",
    "  , 'grp_7_days'\n",
    "  , 'grp_8_days'\n",
    "  , 'unaligned_days'\n",
    "#   , 'is_unaligned'\n",
    "  , 'tc'\n",
    "  , 'hcbs_tc'\n",
    "  , 'icf_tc'\n",
    "  , 'ip_tc'\n",
    "  , 'rx_tc'\n",
    "  , 'ed_tc'\n",
    "  , 'snf_tc'\n",
    "  , 'out_tc'\n",
    "  , 'pro_tc'\n",
    "  , 'spfac_tc'\n",
    "  , 'amb_tc'\n",
    "  , 'hh_tc'\n",
    "  , 'hosp_tc'\n",
    "  , 'oth_tc'\n",
    "  , 'p_mm'\n",
    "  , 'mm'\n",
    "  , 'hcbs_respite_tc'\n",
    "  , 'hcbs_fam_care_stip_tc'\n",
    "  , 'hcbs_com_trans_tc'\n",
    "  , 'hcbs_educ_train_tc'\n",
    "  , 'hcbs_com_liv_fam_tc'\n",
    "  , 'hcbs_com_liv_tc'\n",
    "  , 'hcbs_attend_care_tc'\n",
    "  , 'hcbs_com_trans_waiv_tc'\n",
    "  , 'hcbs_home_meal_tc'\n",
    "  , 'hcbs_pers_care_tc'\n",
    "  , 'hcbs_ther_behav_tc'\n",
    "  , 'hcbs_unsk_respite_tc'\n",
    "  , 'hcbs_waiv_svc_tc'\n",
    "  , 'ddos'\n",
    "  , 'hcbs_ddos'\n",
    "  , 'icf_ddos'\n",
    "  , 'ip_ddos'\n",
    "  , 'rx_ddos'\n",
    "  , 'ed_ddos'\n",
    "  , 'snf_ddos'\n",
    "  , 'out_ddos'\n",
    "  , 'pro_ddos'\n",
    "  , 'spfac_ddos'\n",
    "  , 'amb_ddos'\n",
    "  , 'hh_ddos'\n",
    "  , 'hosp_ddos'\n",
    "  , 'oth_ddos'\n",
    "  , 'pcp_ddos'\n",
    "  , 'pulmonar_ddos'\n",
    "  , 'cancer_ddos'\n",
    "  , 'ckd_ddos'\n",
    "  , 'esrd_ddos'\n",
    "  , 'hyperlipid_ddos'\n",
    "  , 'diab_ddos'\n",
    "  , 'alzh_ddos'\n",
    "  , 'dementia_ddos'\n",
    "  , 'stroke_ddos'\n",
    "  , 'hypertension_ddos'\n",
    "  , 'fall_ddos'\n",
    "  , 'transplant_ddos'\n",
    "  , 'liver_ddos'\n",
    "  , 'hippfract_ddos'\n",
    "  , 'depression_ddos'\n",
    "  , 'psychosis_ddos'\n",
    "  , 'drug_ddos'\n",
    "  , 'alcohol_ddos'\n",
    "  , 'paralysis_ddos'\n",
    "]\n",
    "annual_feature_columns = [\n",
    "#   , 'lvl_ft'\n",
    "#   , 'is_unaligned_ft'\n",
    "    'unaligned_mm_ft'\n",
    "  , 'is_self_directed_ft'\n",
    "  , 'is_cat0_ft'\n",
    "  , 'is_cat1_ft'\n",
    "  , 'is_cat2_ft'\n",
    "  , 'is_cat3_ft'\n",
    "  , 'is_cat4_ft'\n",
    "  , 'is_lob1_ft'\n",
    "  , 'is_lob2_ft'\n",
    "  , 'is_lob3_ft'\n",
    "  , 'is_grp1_ft'\n",
    "  , 'is_grp2_ft'\n",
    "  , 'is_grp3_ft'\n",
    "  , 'is_grp45678_ft'\n",
    "  , 'sav_pct_ft'\n",
    "  , 'raf_sav_pct_ft'\n",
    "  , 'ds_sav_pct_ft'\n",
    "  , 'ip_sav_pct_ft'\n",
    "  , 'snf_sav_pct_ft'\n",
    "  , 'icf_sav_pct_ft'\n",
    "  , 'ed_sav_pct_ft'\n",
    "  , 'hh_sav_pct_ft'\n",
    "  , 'pro_sav_pct_ft'\n",
    "  , 'out_sav_pct_ft'\n",
    "  , 'savings_ft'\n",
    "  , 'raf_savings_ft'\n",
    "  , 'ds_savings_ft'\n",
    "  , 'ip_savings_ft'\n",
    "  , 'snf_savings_ft'\n",
    "  , 'icf_savings_ft'\n",
    "  , 'ed_savings_ft'\n",
    "  , 'hh_savings_ft'\n",
    "  , 'pro_savings_ft'\n",
    "  , 'out_savings_ft'\n",
    "  , 'tc_ft'\n",
    "  , 'hcbs_atd_pcs_tc_ft'\n",
    "  , 'ip_tc_ft'\n",
    "  , 'snf_tc_ft'\n",
    "  , 'icf_tc_ft'\n",
    "  , 'ed_tc_ft'\n",
    "  , 'hh_tc_ft'\n",
    "  , 'pro_tc_ft'\n",
    "  , 'out_tc_ft'\n",
    "  , 'savings_pmpm_ft' # start pmpms\n",
    "  , 'raf_sav_pmpm_ft'\n",
    "  , 'ds_sav_pmpm_ft'\n",
    "  , 'ip_sav_pmpm_ft'\n",
    "  , 'snf_sav_pmpm_ft'\n",
    "  , 'icf_sav_pmpm_ft'\n",
    "  , 'ed_sav_pmpm_ft'\n",
    "  , 'hh_sav_pmpm_ft'\n",
    "  , 'pro_sav_pmpm_ft'\n",
    "  , 'out_sav_pmpm_ft'\n",
    "  , 'tc_pmpm_ft'\n",
    "  , 'hcbs_attd_pmpm_ft'\n",
    "  , 'ip_pmpm_ft'\n",
    "  , 'snf_pmpm_ft'\n",
    "  , 'icf_pmpm_ft'\n",
    "  , 'ed_pmpm_ft'\n",
    "  , 'hh_pmpm_ft'\n",
    "  , 'pro_pmpm_ft'\n",
    "  , 'out_pmpm_ft'\n",
    "  , 'mm_ft'\n",
    "]\n",
    "target_col = 'savings_tgt'\n",
    "# target_col = 'savings_pmpm_tgt'\n",
    "\n",
    "feature_columns = mom_feature_columns + annual_feature_columns\n",
    "len(feature_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try agg features at year and half year level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fully broken out month over month features\n",
    "def features_mom(df, cols):\n",
    "#     print('building month over month features')\n",
    "    df = df.fillna(0)\n",
    "    pre = df.query(\"period < 0\")\n",
    "    pre= pre.pivot(index='member_id', columns='period', values=cols)\n",
    "    pre.columns = [f'{period}-{name}' for (name, period) in pre.columns]\n",
    "    return pre.fillna(0)\n",
    "features_mom.name = 'MOM'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# agg semi yearly_features\n",
    "def features_semi_annual(df, cols):\n",
    "#     print('building semi annual features')\n",
    "    df = df.fillna(0)\n",
    "    pre = df.query(\"period < 0\")\n",
    "    h1 = pre.query('period < -6').groupby('member_id')\n",
    "    h2 = pre.query('period >= -6').groupby('member_id')\n",
    "\n",
    "    h1 = h1[cols].sum()\n",
    "    h2 = h2[cols].sum()\n",
    "\n",
    "    features_h1 = np.divide(h1[cols],  h1[['p_mm']])\n",
    "    features_h2 = np.divide(h2[cols],  h2[['p_mm']])\n",
    "    res = features_h2.merge(features_h1, left_index=True, right_index=True, suffixes=('_h2', '_h1'))\n",
    "    return res.fillna(0)\n",
    "features_semi_annual.name = 'Semi Annual'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# agg yearly_features\n",
    "def features_annual(df, cols):\n",
    "#     print('building annual features')\n",
    "    df = df.fillna(0)\n",
    "    pre = df.query(\"period < 0\").groupby('member_id')\n",
    "    pre_sums = pre[cols].sum()\n",
    "    res = np.divide(pre_sums[cols],  pre_sums[['p_mm']])\n",
    "    return res.fillna(0)\n",
    "features_annual.name = 'Annual'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_feature_importance(regr, cols, max_cols=20):\n",
    "    print('Feature Importance')\n",
    "    i = 0\n",
    "    for imp, feat in sorted([(b, a) for a, b in zip(cols, regr.feature_importances_)], reverse=True):\n",
    "        if imp > 0.001:\n",
    "            print('%0.3f: %s' % (imp, feat))\n",
    "            i += 1\n",
    "        if i > max_cols:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_miss_ided(df, y_test, preds):\n",
    "    id_pop_size = 500\n",
    "    test_df = pd.DataFrame(y_test).assign(pred=preds)\n",
    "    simulated_n_id = int((id_pop_size / df.shape[0]) * test_df.shape[0])\n",
    "\n",
    "    act_top = test_df.sort_values(target_col, ascending=False).iloc[:simulated_n_id]\n",
    "    pred_top = test_df.sort_values('pred', ascending=False).iloc[:simulated_n_id]\n",
    "    \n",
    "    pre_top = df.groupby('member_id').first().sort_values('savings_ft', ascending=False).iloc[:id_pop_size]\n",
    "    post_top = df.groupby('member_id').first().sort_values(target_col, ascending=False).iloc[:id_pop_size]\n",
    "    \n",
    "    print(f'Miss IDed: {act_top.index.difference(pred_top.index).shape[0] * 100.0 / simulated_n_id}%')\n",
    "    print(f'Rul Miss IDed: {post_top.index.difference(pre_top.index).shape[0] * 100.0 / id_pop_size}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Try training three separate models on the three targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lvl = '1. h'\n",
    "\n",
    "df = data.loc[data.lvl_tgt == lvl]\n",
    "\n",
    "targets_df = df[['member_id', 'savings_tgt', 'raf_savings_tgt', 'ds_savings_tgt']].groupby('member_id').first()\n",
    "targets_df = targets_df.assign(med_savings_tgt=targets_df.savings_tgt - targets_df.ds_savings_tgt - targets_df.raf_savings_tgt)\n",
    "targets_df = targets_df[['med_savings_tgt', 'raf_savings_tgt', 'ds_savings_tgt', 'savings_tgt']]\n",
    "\n",
    "features_df = features_annual(df, mom_feature_columns)\n",
    "pre_annual = df.query(\"period < 0\")[annual_feature_columns + ['member_id']].groupby('member_id').first()\n",
    "\n",
    "\n",
    "features_df = features_df.merge(pre_annual, left_index=True, right_index=True)\n",
    "features_df.fillna(0, inplace=True)\n",
    "\n",
    "\n",
    "# order features and targets by member id, make sure they line up perfectly\n",
    "features_df.sort_index(inplace=True)\n",
    "targets_df.sort_index(inplace=True)\n",
    "assert sum(targets_df.index - features_df.index) == 0\n",
    "\n",
    "# train test split\n",
    "# target_col = 'savings_tgt'\n",
    "X_train, X_test, y_train, y_test = train_test_split(features_df, targets_df, test_size=test_set_pct, random_state=seed)\n",
    "\n",
    "med_gb = GradientBoostingRegressor(random_state=seed)\n",
    "raf_gb = GradientBoostingRegressor(random_state=seed)\n",
    "ds_gb = GradientBoostingRegressor(random_state=seed)\n",
    "\n",
    "med_gb.fit(X_train, y_train.values[:,0])\n",
    "raf_gb.fit(X_train, y_train.values[:,1])\n",
    "ds_gb.fit(X_train, y_train.values[:,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "verbose = True\n",
    "preds = med_gb.predict(X_test) + raf_gb.predict(X_test) + ds_gb.predict(X_test)\n",
    "\n",
    "# r2_score = gb.score(X_test, y_test)\n",
    "error = np.abs(y_test.savings_tgt - preds)\n",
    "mean_hrs_error = error.mean()\n",
    "median_hrs_error = error.median()\n",
    "\n",
    "\n",
    "# print(f'R^2 Score: {r2_score}')\n",
    "print(f'Mean absolute $ error: {mean_hrs_error}')\n",
    "print(f'Median absolute $ error: {median_hrs_error}')\n",
    "# get_miss_ided(df, y_test, preds)\n",
    "# print_feature_importance(gb, features_df.columns)\n",
    "if verbose:\n",
    "    fig, ax = plt.subplots(nrows=1, figsize=(20,10))\n",
    "    ax.scatter(preds, y_test.savings_tgt)\n",
    "    ax.set_xlabel('preds')\n",
    "    ax.set_ylabel('actual');\n",
    "    ax.set_title(f'Predicted vs actual savings')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kitchen sink of features, ridge reg\n",
    "Result: better than previous approach, slightly better than rf and untuned boosted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lvl = '1. h'\n",
    "\n",
    "df = data.loc[data.lvl_tgt == lvl]\n",
    "\n",
    "targets_df = df[['member_id', target_col]].groupby('member_id').first()\n",
    "\n",
    "features_df = features_annual(df, mom_feature_columns)\n",
    "pre_annual = df.query(\"period < 0\")[annual_feature_columns + ['member_id']].groupby('member_id').first()\n",
    "\n",
    "\n",
    "features_df = features_df.merge(pre_annual, left_index=True, right_index=True)\n",
    "features_df.fillna(0, inplace=True)\n",
    "\n",
    "\n",
    "# order features and targets by member id, make sure they line up perfectly\n",
    "features_df.sort_index(inplace=True)\n",
    "targets_df.sort_index(inplace=True)\n",
    "assert sum(targets_df.index - features_df.index) == 0\n",
    "\n",
    "# train test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(features_df, targets_df[target_col], test_size=test_set_pct, random_state=seed)\n",
    "\n",
    "from sklearn.linear_model import Ridge\n",
    "gb = Ridge(alpha=1.0, normalize=True)\n",
    "# gb = GradientBoostingRegressor(random_state=seed)\n",
    "# gb = RandomForestRegressor(random_state=seed)\n",
    "\n",
    "gb.fit(X_train, y_train)\n",
    "verbose = True\n",
    "preds = gb.predict(X_test)\n",
    "r2_score = gb.score(X_test, y_test)\n",
    "error = np.abs(y_test - preds)\n",
    "mean_hrs_error = error.mean()\n",
    "median_hrs_error = error.median()\n",
    "\n",
    "\n",
    "print(f'R^2 Score: {r2_score}')\n",
    "print(f'Mean absolute $ error: {mean_hrs_error}')\n",
    "print(f'Median absolute $ error: {median_hrs_error}')\n",
    "get_miss_ided(df,y_test, preds)\n",
    "print('Feature Importance')\n",
    "i = 0\n",
    "for imp, feat in sorted([(b, a) for a, b in zip(features_df.columns, gb.coef_)], reverse=True):\n",
    "    if imp > 0.001:\n",
    "        print('%0.3f: %s' % (imp, feat))\n",
    "        i += 1\n",
    "    if i > 20:\n",
    "        break\n",
    "\n",
    "if verbose:\n",
    "    fig, ax = plt.subplots(nrows=1, figsize=(20,10))\n",
    "    ax.scatter(preds, y_test)\n",
    "    ax.set_xlabel('preds')\n",
    "    ax.set_ylabel('actual');\n",
    "    ax.set_title(f'Predicted vs actual savings')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kitchen sink of features, boosted tree\n",
    "Result: better than previous approach, slightly worse than RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lvl = '1. h'\n",
    "\n",
    "df = data.loc[data.lvl_tgt == lvl]\n",
    "\n",
    "targets_df = df[['member_id', target_col]].groupby('member_id').first()\n",
    "\n",
    "features_df = features_annual(df, mom_feature_columns)\n",
    "pre_annual = df.query(\"period < 0\")[annual_feature_columns + ['member_id']].groupby('member_id').first()\n",
    "\n",
    "\n",
    "features_df = features_df.merge(pre_annual, left_index=True, right_index=True)\n",
    "features_df.fillna(0, inplace=True)\n",
    "\n",
    "\n",
    "# order features and targets by member id, make sure they line up perfectly\n",
    "features_df.sort_index(inplace=True)\n",
    "targets_df.sort_index(inplace=True)\n",
    "assert sum(targets_df.index - features_df.index) == 0\n",
    "\n",
    "# train test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(features_df, targets_df[target_col], test_size=test_set_pct, random_state=seed)\n",
    "\n",
    "gb = GradientBoostingRegressor(random_state=seed)\n",
    "#     gb = RandomForestRegressor(random_state=seed)\n",
    "\n",
    "gb.fit(X_train, y_train)\n",
    "verbose = True\n",
    "preds = gb.predict(X_test)\n",
    "r2_score = gb.score(X_test, y_test)\n",
    "error = np.abs(y_test - preds)\n",
    "mean_hrs_error = error.mean()\n",
    "median_hrs_error = error.median()\n",
    "\n",
    "\n",
    "print(f'R^2 Score: {r2_score}')\n",
    "print(f'Mean absolute $ error: {mean_hrs_error}')\n",
    "print(f'Median absolute $ error: {median_hrs_error}')\n",
    "get_miss_ided(df, y_test, preds)\n",
    "print_feature_importance(gb, features_df.columns)\n",
    "\n",
    "if verbose:\n",
    "    fig, ax = plt.subplots(nrows=1, figsize=(20,10))\n",
    "    ax.scatter(preds, y_test)\n",
    "    ax.set_xlabel('preds')\n",
    "    ax.set_ylabel('actual');\n",
    "    ax.set_title(f'Predicted vs actual savings')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kitchen sink of features, boosted tree, max depth = 1\n",
    "Result: best r2 so far"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lvl = '1. h'\n",
    "\n",
    "df = data.loc[data.lvl_tgt == lvl]\n",
    "\n",
    "targets_df = df[['member_id', target_col]].groupby('member_id').first()\n",
    "\n",
    "features_df = features_annual(df, mom_feature_columns)\n",
    "pre_annual = df.query(\"period < 0\")[annual_feature_columns + ['member_id']].groupby('member_id').first()\n",
    "\n",
    "\n",
    "features_df = features_df.merge(pre_annual, left_index=True, right_index=True)\n",
    "features_df.fillna(0, inplace=True)\n",
    "\n",
    "\n",
    "# order features and targets by member id, make sure they line up perfectly\n",
    "features_df.sort_index(inplace=True)\n",
    "targets_df.sort_index(inplace=True)\n",
    "assert sum(targets_df.index - features_df.index) == 0\n",
    "\n",
    "# train test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(features_df, targets_df[target_col], test_size=test_set_pct, random_state=seed)\n",
    "\n",
    "gb = GradientBoostingRegressor(random_state=seed, max_depth=1, min_samples_leaf=2)\n",
    "#     gb = RandomForestRegressor(random_state=seed)\n",
    "\n",
    "gb.fit(X_train, y_train)\n",
    "verbose = True\n",
    "preds = gb.predict(X_test)\n",
    "r2_score = gb.score(X_test, y_test)\n",
    "error = np.abs(y_test - preds)\n",
    "mean_hrs_error = error.mean()\n",
    "median_hrs_error = error.median()\n",
    "\n",
    "\n",
    "print(f'R^2 Score: {r2_score}')\n",
    "print(f'Mean absolute $ error: {mean_hrs_error}')\n",
    "print(f'Median absolute $ error: {median_hrs_error}')\n",
    "get_miss_ided(df, y_test, preds)\n",
    "print_feature_importance(gb, features_df.columns)\n",
    "\n",
    "if verbose:\n",
    "    fig, ax = plt.subplots(nrows=1, figsize=(20,10))\n",
    "    ax.scatter(preds, y_test)\n",
    "    ax.set_xlabel('preds')\n",
    "    ax.set_ylabel('actual');\n",
    "    ax.set_title(f'Predicted vs actual savings')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Just the new anual features\n",
    "Result: not quite as good as the kitchen sink"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lvl = '1. h'\n",
    "\n",
    "df = data.loc[data.lvl_tgt == lvl]\n",
    "\n",
    "targets_df = df[['member_id', target_col]].groupby('member_id').first()\n",
    "\n",
    "# features_df = features_annual(df, mom_feature_columns)\n",
    "features_df = df.query(\"period < 0\")[annual_feature_columns + ['member_id']].groupby('member_id').first()\n",
    "features_df.fillna(0, inplace=True)\n",
    "\n",
    "\n",
    "# order features and targets by member id, make sure they line up perfectly\n",
    "features_df.sort_index(inplace=True)\n",
    "targets_df.sort_index(inplace=True)\n",
    "assert sum(targets_df.index - features_df.index) == 0\n",
    "\n",
    "# train test split\n",
    "target_col = 'savings_tgt'\n",
    "X_train, X_test, y_train, y_test = train_test_split(features_df, targets_df[target_col], test_size=test_set_pct, random_state=seed)\n",
    "\n",
    "gb = GradientBoostingRegressor(random_state=seed)\n",
    "# gb = GradientBoostingRegressor(random_state=seed, max_depth=1)\n",
    "#     gb = RandomForestRegressor(random_state=seed)\n",
    "\n",
    "gb.fit(X_train, y_train)\n",
    "verbose = True\n",
    "preds = gb.predict(X_test)\n",
    "r2_score = gb.score(X_test, y_test)\n",
    "error = np.abs(y_test - preds)\n",
    "mean_hrs_error = error.mean()\n",
    "median_hrs_error = error.median()\n",
    "\n",
    "\n",
    "print(f'R^2 Score: {r2_score}')\n",
    "print(f'Mean absolute $ error: {mean_hrs_error}')\n",
    "print(f'Median absolute $ error: {median_hrs_error}')\n",
    "get_miss_ided(df, y_test, preds)\n",
    "print_feature_importance(gb, features_df.columns)\n",
    "\n",
    "if verbose:\n",
    "    fig, ax = plt.subplots(nrows=1, figsize=(20,10))\n",
    "    ax.scatter(preds, y_test)\n",
    "    ax.set_xlabel('preds')\n",
    "    ax.set_ylabel('actual');\n",
    "    ax.set_title(f'Predicted vs actual savings')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raise Exception(\"Stop here when running all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_level_feature_space = False\n",
    "if search_level_feature_space:\n",
    "    levels = ('1. h', '2. m', '3. l')\n",
    "    feature_funcs = (features_mom, features_semi_annual, features_annual)\n",
    "    for lvl in levels:\n",
    "        df = data.loc[data.lvl_tgt == lvl]\n",
    "\n",
    "        targets_df = df[['member_id', target_col]].groupby('member_id').first()\n",
    "        targets_df.fillna(0, inplace=True)\n",
    "\n",
    "        for feat_func in feature_funcs: \n",
    "            print('Level: ', lvl)\n",
    "            print('Features: ', feat_func.name)\n",
    "            df = df.fillna(0)\n",
    "            features_df = feat_func(df, feature_columns)\n",
    "            model = train_and_test(features_df, targets_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = data.loc[data.lvl_tgt == '1. h']\n",
    "\n",
    "targets_df = df[['member_id', target_col]].groupby('member_id').first()\n",
    "targets_df.fillna(0, inplace=True)\n",
    "\n",
    "df = df.fillna(0)\n",
    "features_df = features_annual(df, feature_columns)\n",
    "model = train_and_test(features_df, targets_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model.predict(features_df)\n",
    "top_500_preds = features_df.assign(pred=preds).sort_values('pred', ascending=False).iloc[:500][['pred']]\n",
    "id_pop = data.loc[(data.lvl_tgt == '1. h')]\n",
    "# id_pop = data.loc[(data.lvl_tgt == lvl) & (data.period > 0)]\n",
    "id_pop = id_pop.set_index('member_id')\n",
    "id_pop = id_pop.merge(top_500_preds, left_index=True, right_index=True) \n",
    "id_pop = id_pop.merge(targets_df, left_index=True, right_index=True) \n",
    "id_pop = id_pop.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_pop.head()\n",
    "# features_df.assign(pred=preds)[['pred']].to_csv('../outputs/h_preds.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tcs = [c for c in features_df.columns if c[-3:] == '_tc'] + ['tc']\n",
    "tcs = [c for c in tcs if len(c) < 8 or c[:5] != 'hcbs_']\n",
    "\n",
    "g = sns.relplot(\n",
    "    x=\"period\",\n",
    "    y=\"value\",\n",
    "    hue=\"variable\",\n",
    "    kind=\"line\",\n",
    "    data=id_pop.melt(id_vars=['period'], value_vars=tcs),\n",
    "    height=12,\n",
    "    aspect=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tune hyperparameters: didn't see much benifit, takes about 30 minutes to run\n",
    "\n",
    "# lvl  = '1. h'\n",
    "# df = data.loc[data.lvl_tgt == lvl]\n",
    "# df = df.fillna(0)\n",
    "\n",
    "# targets_df = df[['member_id', target_col]].groupby('member_id').first()\n",
    "# feats_df = features_annual(df, feature_columns)\n",
    "\n",
    "# feats_df.sort_index(inplace=True)\n",
    "# targets_df.sort_index(inplace=True)\n",
    "# assert sum(targets_df.index - feats_df.index) == 0\n",
    "\n",
    "# # train test split\n",
    "# target_col = 'savings_tgt'\n",
    "# X_train, X_test, y_train, y_test = train_test_split(feats_df, targets_df[target_col], test_size=test_set_pct, random_state=seed)\n",
    "\n",
    "# gb = GradientBoostingRegressor(random_state=seed)\n",
    "\n",
    "# grid = {\n",
    "#     'learning_rate': [0.001, 0.01, 0.1, 0.2],\n",
    "#     'n_estimators': [10, 100, 500, 1000],\n",
    "#     'max_depth': [2, 3, 4, 5, 10],\n",
    "#     'min_samples_leaf': [1, 2, 3, 4, 5],\n",
    "# }\n",
    "\n",
    "# clf = GridSearchCV(gb, grid, n_jobs=os.cpu_count())\n",
    "\n",
    "# search = clf.fit(X_train, y_train)\n",
    "\n",
    "# cv_res = pd.DataFrame(search.cv_results_)\n",
    "# cv_res.sort_values('rank_test_score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_name = cb_utils.save_model(model, '1_xgb_cat_savings', {'name': '1_xgb_cat_savings', 'features': list(features_df.columns)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model trained on mab 5\n",
    "model_name = '20200731_153512_1_xgb_cat_savings'\n",
    "model, meta = cb_utils.load_model(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cb_utils.save_scores(final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test on a different population\n",
    "query = \"SELECT * FROM cb.vw_mab_training_data WHERE mab_id = 6;\"\n",
    "mab6 = cb_utils.sql_query_to_df(query, use_cache=use_cache)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets_df = mab6[['member_id', target_col]].groupby('member_id').first()\n",
    "targets_df.fillna(0, inplace=True)\n",
    "\n",
    "mab6 = mab6.fillna(0)\n",
    "features_df = features_annual(mab6, feature_columns)\n",
    "features_df.sort_index(inplace=True)\n",
    "targets_df.sort_index(inplace=True)\n",
    "\n",
    "\n",
    "preds = model.predict(features_df)\n",
    "r2_score = model.score(features_df, targets_df[target_col])\n",
    "\n",
    "error = np.abs(targets_df[target_col] - preds)\n",
    "mean_hrs_error = error.mean()\n",
    "median_hrs_error = error.median()\n",
    "\n",
    "print('Testing MAB 6 data on model trained with mab 5')\n",
    "print(f'R^2 Score: {r2_score}')\n",
    "print(f'Mean absolute $ error: {mean_hrs_error}')\n",
    "print(f'Median absolute $ error: {median_hrs_error}')\n",
    "\n",
    "fig, ax = plt.subplots(nrows=1, figsize=(20,10))\n",
    "ax.scatter(preds, targets_df[target_col])\n",
    "ax.set_xlabel('preds')\n",
    "ax.set_ylabel('actual');\n",
    "ax.set_title(f'Predicted vs actual savings')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# try training on early set \n",
    "query = \"SELECT * FROM cb.vw_mab_training_data WHERE mab_id = 6;\"\n",
    "mab6 = cb_utils.sql_query_to_df(query, use_cache=use_cache)\n",
    "\n",
    "df = mab6.loc[data.lvl_tgt == '1. h']\n",
    "\n",
    "targets_df = df[['member_id', target_col]].groupby('member_id').first()\n",
    "targets_df.fillna(0, inplace=True)\n",
    "\n",
    "df = df.fillna(0)\n",
    "features_df = features_annual(df, feature_columns)\n",
    "model = train_and_test(features_df, targets_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
