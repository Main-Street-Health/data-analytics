{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "import random\n",
    "import collections\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, BaggingRegressor\n",
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "sys.path.append('../src')\n",
    "import cb_utils\n",
    "\n",
    "sns.set(style=\"darkgrid\")\n",
    "pd.options.display.max_columns = 500\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from pymc3 import  *\n",
    "import theano\n",
    "import pandas as pd\n",
    "# from statsmodels.formula.api import glm as glm_sm\n",
    "# import statsmodels.api as sm\n",
    "from pandas.plotting import scatter_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# configuration\n",
    "scoring_run_id = 1\n",
    "use_cache = True\n",
    "seed = random.randint(0, 100)\n",
    "test_set_pct = 0.2\n",
    "print(f'Seed: {seed}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "query = \"SELECT * FROM cb.vw_mab_training_data WHERE mab_id = 1;\"\n",
    "data = cb_utils.sql_query_to_df(query, use_cache=use_cache)\n",
    "data.fillna(0, inplace=True)\n",
    "\n",
    "query = \"SELECT * FROM cb.vw_mab_training_data WHERE mab_id = 2;\"\n",
    "mab2 = cb_utils.sql_query_to_df(query, use_cache=use_cache)\n",
    "mab2.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mom_feature_columns = [\n",
    "    'lob_1_days'\n",
    "  , 'lob_2_days'\n",
    "  , 'lob_3_days'\n",
    "  , 'grp_1_days'\n",
    "  , 'grp_2_days'\n",
    "  , 'grp_3_days'\n",
    "  , 'grp_5_days'\n",
    "  , 'grp_6_days'\n",
    "  , 'grp_7_days'\n",
    "  , 'grp_8_days'\n",
    "  , 'unaligned_days'\n",
    "#   , 'is_unaligned'\n",
    "  , 'tc'\n",
    "  , 'hcbs_tc'\n",
    "  , 'icf_tc'\n",
    "  , 'ip_tc'\n",
    "  , 'rx_tc'\n",
    "  , 'ed_tc'\n",
    "  , 'snf_tc'\n",
    "  , 'out_tc'\n",
    "  , 'pro_tc'\n",
    "  , 'spfac_tc'\n",
    "  , 'amb_tc'\n",
    "  , 'hh_tc'\n",
    "  , 'hosp_tc'\n",
    "  , 'oth_tc'\n",
    "  , 'p_mm'\n",
    "  , 'mm'\n",
    "  , 'hcbs_respite_tc'\n",
    "  , 'hcbs_fam_care_stip_tc'\n",
    "  , 'hcbs_com_trans_tc'\n",
    "  , 'hcbs_educ_train_tc'\n",
    "  , 'hcbs_com_liv_fam_tc'\n",
    "  , 'hcbs_com_liv_tc'\n",
    "  , 'hcbs_attend_care_tc'\n",
    "  , 'hcbs_com_trans_waiv_tc'\n",
    "  , 'hcbs_home_meal_tc'\n",
    "  , 'hcbs_pers_care_tc'\n",
    "  , 'hcbs_ther_behav_tc'\n",
    "  , 'hcbs_unsk_respite_tc'\n",
    "  , 'hcbs_waiv_svc_tc'\n",
    "  , 'ddos'\n",
    "  , 'hcbs_ddos'\n",
    "  , 'icf_ddos'\n",
    "  , 'ip_ddos'\n",
    "  , 'rx_ddos'\n",
    "  , 'ed_ddos'\n",
    "  , 'snf_ddos'\n",
    "  , 'out_ddos'\n",
    "  , 'pro_ddos'\n",
    "  , 'spfac_ddos'\n",
    "  , 'amb_ddos'\n",
    "  , 'hh_ddos'\n",
    "  , 'hosp_ddos'\n",
    "  , 'oth_ddos'\n",
    "  , 'pcp_ddos'\n",
    "  , 'pulmonar_ddos'\n",
    "  , 'cancer_ddos'\n",
    "  , 'ckd_ddos'\n",
    "  , 'esrd_ddos'\n",
    "  , 'hyperlipid_ddos'\n",
    "  , 'diab_ddos'\n",
    "  , 'alzh_ddos'\n",
    "  , 'dementia_ddos'\n",
    "  , 'stroke_ddos'\n",
    "  , 'hypertension_ddos'\n",
    "  , 'fall_ddos'\n",
    "  , 'transplant_ddos'\n",
    "  , 'liver_ddos'\n",
    "  , 'hippfract_ddos'\n",
    "  , 'depression_ddos'\n",
    "  , 'psychosis_ddos'\n",
    "  , 'drug_ddos'\n",
    "  , 'alcohol_ddos'\n",
    "  , 'paralysis_ddos'\n",
    "]\n",
    "annual_feature_columns = [\n",
    "#   , 'lvl_ft'\n",
    "#   , 'is_unaligned_ft'\n",
    "    'unaligned_mm_ft'\n",
    "  , 'is_self_directed_ft'\n",
    "  , 'is_cat0_ft'\n",
    "  , 'is_cat1_ft'\n",
    "  , 'is_cat2_ft'\n",
    "  , 'is_cat3_ft'\n",
    "  , 'is_cat4_ft'\n",
    "  , 'is_lob1_ft'\n",
    "  , 'is_lob2_ft'\n",
    "  , 'is_lob3_ft'\n",
    "  , 'is_grp1_ft'\n",
    "  , 'is_grp2_ft'\n",
    "  , 'is_grp3_ft'\n",
    "  , 'is_grp45678_ft'\n",
    "  , 'sav_pct_ft'\n",
    "  , 'raf_sav_pct_ft'\n",
    "  , 'ds_sav_pct_ft'\n",
    "  , 'ip_sav_pct_ft'\n",
    "  , 'snf_sav_pct_ft'\n",
    "  , 'icf_sav_pct_ft'\n",
    "  , 'ed_sav_pct_ft'\n",
    "  , 'hh_sav_pct_ft'\n",
    "  , 'pro_sav_pct_ft'\n",
    "  , 'out_sav_pct_ft'\n",
    "  , 'savings_ft'\n",
    "  , 'raf_savings_ft'\n",
    "  , 'ds_savings_ft'\n",
    "  , 'ip_savings_ft'\n",
    "  , 'snf_savings_ft'\n",
    "  , 'icf_savings_ft'\n",
    "  , 'ed_savings_ft'\n",
    "  , 'hh_savings_ft'\n",
    "  , 'pro_savings_ft'\n",
    "  , 'out_savings_ft'\n",
    "  , 'tc_ft'\n",
    "  , 'hcbs_atd_pcs_tc_ft'\n",
    "  , 'ip_tc_ft'\n",
    "  , 'snf_tc_ft'\n",
    "  , 'icf_tc_ft'\n",
    "  , 'ed_tc_ft'\n",
    "  , 'hh_tc_ft'\n",
    "  , 'pro_tc_ft'\n",
    "  , 'out_tc_ft'\n",
    "  , 'savings_pmpm_ft' # start pmpms\n",
    "  , 'raf_sav_pmpm_ft'\n",
    "  , 'ds_sav_pmpm_ft'\n",
    "  , 'ip_sav_pmpm_ft'\n",
    "  , 'snf_sav_pmpm_ft'\n",
    "  , 'icf_sav_pmpm_ft'\n",
    "  , 'ed_sav_pmpm_ft'\n",
    "  , 'hh_sav_pmpm_ft'\n",
    "  , 'pro_sav_pmpm_ft'\n",
    "  , 'out_sav_pmpm_ft'\n",
    "  , 'tc_pmpm_ft'\n",
    "  , 'hcbs_attd_pmpm_ft'\n",
    "  , 'ip_pmpm_ft'\n",
    "  , 'snf_pmpm_ft'\n",
    "  , 'icf_pmpm_ft'\n",
    "  , 'ed_pmpm_ft'\n",
    "  , 'hh_pmpm_ft'\n",
    "  , 'pro_pmpm_ft'\n",
    "  , 'out_pmpm_ft'\n",
    "  , 'mm_ft'\n",
    "  , 'age'\n",
    "  , 'is_male'\n",
    "]\n",
    "target_col = 'savings_tgt'\n",
    "# target_col = 'savings_pmpm_tgt'\n",
    "\n",
    "feature_columns = mom_feature_columns + annual_feature_columns\n",
    "len(feature_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try agg features at year and half year level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fully broken out month over month features\n",
    "def features_mom(df, cols):\n",
    "#     print('building month over month features')\n",
    "    df = df.fillna(0)\n",
    "    pre = df.query(\"period < 0\")\n",
    "    pre= pre.pivot(index='member_id', columns='period', values=cols)\n",
    "    pre.columns = [f'{period}-{name}' for (name, period) in pre.columns]\n",
    "    return pre.fillna(0)\n",
    "features_mom.name = 'MOM'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# agg semi yearly_features\n",
    "def features_semi_annual(df, cols):\n",
    "#     print('building semi annual features')\n",
    "    df = df.fillna(0)\n",
    "    pre = df.query(\"period < 0\")\n",
    "    h1 = pre.query('period < -6').groupby('member_id')\n",
    "    h2 = pre.query('period >= -6').groupby('member_id')\n",
    "\n",
    "    h1 = h1[cols].sum()\n",
    "    h2 = h2[cols].sum()\n",
    "\n",
    "    features_h1 = np.divide(h1[cols],  h1[['p_mm']])\n",
    "    features_h2 = np.divide(h2[cols],  h2[['p_mm']])\n",
    "    res = features_h2.merge(features_h1, left_index=True, right_index=True, suffixes=('_h2', '_h1'))\n",
    "    return res.fillna(0)\n",
    "features_semi_annual.name = 'Semi Annual'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# agg yearly_features\n",
    "def features_annual(df, cols):\n",
    "#     print('building annual features')\n",
    "    df = df.fillna(0)\n",
    "    pre = df.query(\"period < 0\").groupby('member_id')\n",
    "    pre_sums = pre[cols].sum()\n",
    "    res = np.divide(pre_sums[cols],  pre_sums[['p_mm']])\n",
    "    return res.fillna(0)\n",
    "features_annual.name = 'Annual'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_feature_importance(regr, cols, max_cols=20):\n",
    "    print('Feature Importance')\n",
    "    i = 0\n",
    "    for imp, feat in sorted([(b, a) for a, b in zip(cols, regr.feature_importances_)], reverse=True):\n",
    "        if imp > 0.001:\n",
    "            print('%0.3f: %s' % (imp, feat))\n",
    "            i += 1\n",
    "        if i > max_cols:\n",
    "            break\n",
    "            \n",
    "def print_coef_importance(regr, cols, max_cols=20):\n",
    "    print('Feature Importance')\n",
    "    i = 0\n",
    "    for imp, feat in sorted([(b, a) for a, b in zip(cols, regr.coef_)], reverse=True):\n",
    "        if imp > 0.001:\n",
    "            print('%0.3f: %s' % (imp, feat))\n",
    "            i += 1\n",
    "        if i > max_cols:\n",
    "            break\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_miss_ided(X_test, y_test, preds, verbose=True):\n",
    "    id_pop_size = 100 # test split is 20%, 20% of 500 == 100\n",
    "    test_df = X_test.assign(target=y_test, pred=preds)\n",
    "    \n",
    "    pre_rule_id = test_df.sort_values('savings_ft', ascending=False).iloc[:id_pop_size]\n",
    "    perf_id = test_df.sort_values('target', ascending=False).iloc[:id_pop_size]\n",
    "    pred_id = test_df.sort_values('pred', ascending=False).iloc[:id_pop_size]\n",
    "    \n",
    "    pred_misses = perf_id.index.difference(pred_id.index).shape[0]\n",
    "    rule_misses = perf_id.index.difference(pre_rule_id.index).shape[0]\n",
    "    \n",
    "    if verbose:\n",
    "        print(f'Miss IDed: {pred_misses * 100.0 / id_pop_size}%')\n",
    "        print(f'Rule Miss IDed: {rule_misses * 100.0 / id_pop_size}%')\n",
    "    return pred_misses, rule_misses "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multilevel modeling\n",
    "Couldn't get pymc3 to work due to theano issues\n",
    "training separate models for lob's didn't improve performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model to get features\n",
    "model_name = '20200803_121030_3_m_savings_lr_1000_bag_pre_processed'\n",
    "models, meta = cb_utils.load_model(model_name)\n",
    "feature_cols = meta['features']\n",
    "\n",
    "mom_feats = [c for c in feature_cols if c in mom_feature_columns]\n",
    "annual_feats = [c for c in feature_cols if c in annual_feature_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lvl = '1. h'\n",
    "lvl = '2. m'\n",
    "df = data.loc[data.lvl_tgt == lvl]\n",
    "\n",
    "targets_df = df[['member_id', target_col]].groupby('member_id').first()\n",
    "\n",
    "features_df = features_annual(df, mom_feats)\n",
    "pre_annual = df.query(\"period < 0\")[annual_feats + ['member_id']].groupby('member_id').first()\n",
    "\n",
    "features_df = features_df.merge(pre_annual, left_index=True, right_index=True)\n",
    "features_df.fillna(0, inplace=True)\n",
    "\n",
    "# add multi level model group column\n",
    "features_df = features_df.assign(model_grp=99)\n",
    "features_df.loc[(features_df.is_lob1_ft == 1) & (features_df.is_grp1_ft == 1), 'model_grp'] = 0\n",
    "features_df.loc[(features_df.is_lob1_ft == 1) & (features_df.is_grp2_ft == 1), 'model_grp'] = 1\n",
    "features_df.loc[(features_df.is_lob1_ft == 1) & (features_df.is_grp3_ft == 1), 'model_grp'] = 2\n",
    "features_df.loc[(features_df.is_lob2_ft == 1) & (features_df.is_grp1_ft == 1), 'model_grp'] = 3\n",
    "features_df.loc[(features_df.is_lob2_ft == 1) & (features_df.is_grp2_ft == 1), 'model_grp'] = 4\n",
    "features_df.loc[(features_df.is_lob2_ft == 1) & (features_df.is_grp3_ft == 1), 'model_grp'] = 5\n",
    "features_df.loc[(features_df.is_lob3_ft == 1) & (features_df.is_grp1_ft == 1), 'model_grp'] = 6\n",
    "features_df.loc[(features_df.is_lob3_ft == 1) & (features_df.is_grp2_ft == 1), 'model_grp'] = 7\n",
    "features_df.loc[(features_df.is_lob3_ft == 1) & (features_df.is_grp3_ft == 1), 'model_grp'] = 8\n",
    "assert features_df.loc[features_df.model_grp > 8].shape[0] == 0\n",
    "\n",
    "# order features and targets by member id, make sure they line up perfectly\n",
    "features_df.sort_index(inplace=True)\n",
    "targets_df.sort_index(inplace=True)\n",
    "assert sum(targets_df.index - features_df.index) == 0\n",
    "\n",
    "# train test split\n",
    "# X_train, X_test, y_train, y_test = train_test_split(features_df, targets_df[target_col], test_size=test_set_pct, random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BaggingRegressor(base_estimator=Ridge(alpha=1.0, normalize=True), n_estimators=1000, oob_score=True, n_jobs=os.cpu_count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(features_df, targets_df[target_col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test model on 2017\n",
    "df = mab2.loc[data.lvl_tgt == lvl]\n",
    "targets_df = df[['member_id', target_col]].groupby('member_id').first()\n",
    "\n",
    "features_df = features_annual(df, mom_feats)\n",
    "pre_annual = df.query(\"period < 0\")[annual_feats + ['member_id']].groupby('member_id').first()\n",
    "\n",
    "features_df = features_df.merge(pre_annual, left_index=True, right_index=True)\n",
    "features_df.fillna(0, inplace=True)\n",
    "\n",
    "# add multi level model group column\n",
    "features_df = features_df.assign(model_grp=99)\n",
    "features_df.loc[(features_df.is_lob1_ft == 1) & (features_df.is_grp1_ft == 1), 'model_grp'] = 0\n",
    "features_df.loc[(features_df.is_lob1_ft == 1) & (features_df.is_grp2_ft == 1), 'model_grp'] = 1\n",
    "features_df.loc[(features_df.is_lob1_ft == 1) & (features_df.is_grp3_ft == 1), 'model_grp'] = 2\n",
    "features_df.loc[(features_df.is_lob2_ft == 1) & (features_df.is_grp1_ft == 1), 'model_grp'] = 3\n",
    "features_df.loc[(features_df.is_lob2_ft == 1) & (features_df.is_grp2_ft == 1), 'model_grp'] = 4\n",
    "features_df.loc[(features_df.is_lob2_ft == 1) & (features_df.is_grp3_ft == 1), 'model_grp'] = 5\n",
    "features_df.loc[(features_df.is_lob3_ft == 1) & (features_df.is_grp1_ft == 1), 'model_grp'] = 6\n",
    "features_df.loc[(features_df.is_lob3_ft == 1) & (features_df.is_grp2_ft == 1), 'model_grp'] = 7\n",
    "features_df.loc[(features_df.is_lob3_ft == 1) & (features_df.is_grp3_ft == 1), 'model_grp'] = 8\n",
    "assert features_df.loc[features_df.model_grp > 8].shape[0] == 0\n",
    "\n",
    "# order features and targets by member id, make sure they line up perfectly\n",
    "features_df.sort_index(inplace=True)\n",
    "targets_df.sort_index(inplace=True)\n",
    "assert sum(targets_df.index - features_df.index) == 0\n",
    "\n",
    "preds = model.predict(features_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_misses, rule_misses = get_miss_ided(features_df, targets_df[target_col], preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# try separate models for lobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = data.loc[data.lvl_tgt == lvl]\n",
    "\n",
    "targets_df = df[['member_id', target_col]].groupby('member_id').first()\n",
    "\n",
    "features_df = features_annual(df, mom_feats)\n",
    "pre_annual = df.query(\"period < 0\")[annual_feats + ['member_id']].groupby('member_id').first()\n",
    "\n",
    "features_df = features_df.merge(pre_annual, left_index=True, right_index=True)\n",
    "features_df.fillna(0, inplace=True)\n",
    "\n",
    "# add multi level model group column\n",
    "features_df = features_df.assign(model_grp=99)\n",
    "features_df.loc[(features_df.is_lob1_ft == 1) & (features_df.is_grp1_ft == 1), 'model_grp'] = 0\n",
    "features_df.loc[(features_df.is_lob1_ft == 1) & (features_df.is_grp2_ft == 1), 'model_grp'] = 1\n",
    "features_df.loc[(features_df.is_lob1_ft == 1) & (features_df.is_grp3_ft == 1), 'model_grp'] = 2\n",
    "features_df.loc[(features_df.is_lob2_ft == 1) & (features_df.is_grp1_ft == 1), 'model_grp'] = 3\n",
    "features_df.loc[(features_df.is_lob2_ft == 1) & (features_df.is_grp2_ft == 1), 'model_grp'] = 4\n",
    "features_df.loc[(features_df.is_lob2_ft == 1) & (features_df.is_grp3_ft == 1), 'model_grp'] = 5\n",
    "features_df.loc[(features_df.is_lob3_ft == 1) & (features_df.is_grp1_ft == 1), 'model_grp'] = 6\n",
    "features_df.loc[(features_df.is_lob3_ft == 1) & (features_df.is_grp2_ft == 1), 'model_grp'] = 7\n",
    "features_df.loc[(features_df.is_lob3_ft == 1) & (features_df.is_grp3_ft == 1), 'model_grp'] = 8\n",
    "assert features_df.loc[features_df.model_grp > 8].shape[0] == 0\n",
    "\n",
    "# order features and targets by member id, make sure they line up perfectly\n",
    "features_df.sort_index(inplace=True)\n",
    "targets_df.sort_index(inplace=True)\n",
    "assert sum(targets_df.index - features_df.index) == 0\n",
    "\n",
    "feats_lob_1 = features_df.query('model_grp < 6')\n",
    "feats_lob_3 = features_df.query('model_grp >= 6')\n",
    "\n",
    "targets_lob_1 = targets_df.loc[feats_lob_1.index]\n",
    "targets_lob_3 = targets_df.loc[feats_lob_3.index]\n",
    "assert feats_lob_1.index.difference(targets_lob_1.index).shape[0] == 0\n",
    "assert feats_lob_3.index.difference(targets_lob_3.index).shape[0] == 0\n",
    "\n",
    "# train test split\n",
    "# X_train, X_test, y_train, y_test = train_test_split(features_df, targets_df[target_col], test_size=test_set_pct, random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lob_1_model = BaggingRegressor(base_estimator=Ridge(alpha=1.0, normalize=True), n_estimators=1000, oob_score=True, n_jobs=os.cpu_count())\n",
    "lob_3_model = BaggingRegressor(base_estimator=Ridge(alpha=1.0, normalize=True), n_estimators=1000, oob_score=True, n_jobs=os.cpu_count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lob_1_model.fit(feats_lob_1, targets_lob_1[target_col])\n",
    "lob_3_model.fit(feats_lob_3, targets_lob_3[target_col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test model on 2017\n",
    "df = mab2.loc[data.lvl_tgt == lvl]\n",
    "targets_df = df[['member_id', target_col]].groupby('member_id').first()\n",
    "\n",
    "features_df = features_annual(df, mom_feats)\n",
    "pre_annual = df.query(\"period < 0\")[annual_feats + ['member_id']].groupby('member_id').first()\n",
    "\n",
    "features_df = features_df.merge(pre_annual, left_index=True, right_index=True)\n",
    "features_df.fillna(0, inplace=True)\n",
    "\n",
    "# add multi level model group column\n",
    "features_df = features_df.assign(model_grp=99)\n",
    "features_df.loc[(features_df.is_lob1_ft == 1) & (features_df.is_grp1_ft == 1), 'model_grp'] = 0\n",
    "features_df.loc[(features_df.is_lob1_ft == 1) & (features_df.is_grp2_ft == 1), 'model_grp'] = 1\n",
    "features_df.loc[(features_df.is_lob1_ft == 1) & (features_df.is_grp3_ft == 1), 'model_grp'] = 2\n",
    "features_df.loc[(features_df.is_lob2_ft == 1) & (features_df.is_grp1_ft == 1), 'model_grp'] = 3\n",
    "features_df.loc[(features_df.is_lob2_ft == 1) & (features_df.is_grp2_ft == 1), 'model_grp'] = 4\n",
    "features_df.loc[(features_df.is_lob2_ft == 1) & (features_df.is_grp3_ft == 1), 'model_grp'] = 5\n",
    "features_df.loc[(features_df.is_lob3_ft == 1) & (features_df.is_grp1_ft == 1), 'model_grp'] = 6\n",
    "features_df.loc[(features_df.is_lob3_ft == 1) & (features_df.is_grp2_ft == 1), 'model_grp'] = 7\n",
    "features_df.loc[(features_df.is_lob3_ft == 1) & (features_df.is_grp3_ft == 1), 'model_grp'] = 8\n",
    "assert features_df.loc[features_df.model_grp > 8].shape[0] == 0\n",
    "\n",
    "# order features and targets by member id, make sure they line up perfectly\n",
    "features_df.sort_index(inplace=True)\n",
    "targets_df.sort_index(inplace=True)\n",
    "assert sum(targets_df.index - features_df.index) == 0\n",
    "feats_lob_1 = features_df.query('model_grp < 6')\n",
    "feats_lob_3 = features_df.query('model_grp >= 6')\n",
    "\n",
    "targets_lob_1 = targets_df.loc[feats_lob_1.index]\n",
    "targets_lob_3 = targets_df.loc[feats_lob_3.index]\n",
    "assert feats_lob_1.index.difference(targets_lob_1.index).shape[0] == 0\n",
    "assert feats_lob_3.index.difference(targets_lob_3.index).shape[0] == 0\n",
    "\n",
    "lob_1_preds = lob_1_model.predict(feats_lob_1)\n",
    "lob_3_preds = lob_3_model.predict(feats_lob_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_misses, rule_misses = get_miss_ided(\n",
    "    pd.concat([feats_lob_1, feats_lob_3], axis=0),\n",
    "    pd.concat([targets_lob_1, targets_lob_3], axis=0),\n",
    "    np.append(lob_1_preds, lob_3_preds)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymc3 import glm, Model, Metropolis, NUTS, sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = X_train\n",
    "y = y_train\n",
    "m_data = {'x': x, 'y': y}\n",
    "with Model() as model:\n",
    "#     lm = glm.LinearComponent.from_formula('y ~ x', data)\n",
    "#     sigma = Uniform('sigma', 0, 20)\n",
    "#     y_obs = Normal('y_obs', mu=lm.y_est, sigma=sigma, observed=y)\n",
    "    GLM.from_formula('y ~ x', m_data)\n",
    "    trace = sample(200, cores=2)\n",
    "\n",
    "plt.figure(figsize=(5, 5))\n",
    "plt.plot(x, y, 'x')\n",
    "plot_posterior_predictive_glm(trace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example\n",
    "\n",
    "size = 50\n",
    "true_intercept = 1\n",
    "true_slope = 2\n",
    "x = np.linspace(0, 1, size)\n",
    "y = true_intercept + x*true_slope + np.random.normal(scale=.5, size=size)\n",
    "data = {'x': x, 'y': y}\n",
    "with Model() as model:\n",
    "    lm = glm.LinearComponent.from_formula('y ~ x', data)\n",
    "    sigma = Uniform('sigma', 0, 20)\n",
    "    y_obs = Normal('y_obs', mu=lm.y_est, sigma=sigma, observed=y)\n",
    "    trace = sample(2000, cores=2)\n",
    "\n",
    "plt.figure(figsize=(5, 5))\n",
    "plt.plot(x, y, 'x')\n",
    "plot_posterior_predictive_glm(trace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with Model() as pooled_model:\n",
    "#     glm('log_radon ~ floor', srrs_mn)\n",
    "#     pooled_trace = sample(1000, NUTS())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train 2018\n",
    "# missed_advantage = []\n",
    "# models = []\n",
    "\n",
    "from sklearn.ensemble import BaggingRegressor\n",
    "\n",
    "# for i in range(10):\n",
    "feature_cols = [c for c, v in cnt.items() if v >= 3]\n",
    "feature_cols = meta['features']\n",
    "mom_feats = [c for c in feature_cols if c in mom_feature_columns]# + ['p_mm']\n",
    "annual_feats = [c for c in feature_cols if c in annual_feature_columns]\n",
    "# print(i, ', '.join(feature_cols))\n",
    "\n",
    "#     lvl = '2. m'\n",
    "lvl = '1. h'\n",
    "df = data.loc[data.lvl_tgt == lvl]\n",
    "\n",
    "targets_df = df[['member_id', target_col]].groupby('member_id').first()\n",
    "\n",
    "features_df = features_annual(df, mom_feats)\n",
    "pre_annual = df.query(\"period < 0\")[annual_feats + ['member_id']].groupby('member_id').first()\n",
    "\n",
    "\n",
    "features_df = features_df.merge(pre_annual, left_index=True, right_index=True)\n",
    "features_df.fillna(0, inplace=True)\n",
    "\n",
    "\n",
    "# order features and targets by member id, make sure they line up perfectly\n",
    "features_df.sort_index(inplace=True)\n",
    "targets_df.sort_index(inplace=True)\n",
    "assert sum(targets_df.index - features_df.index) == 0\n",
    "\n",
    "# train test split\n",
    "# target_col = 'savings_tgt'\n",
    "seed = random.randint(0, 1000)\n",
    "print(f'seed: {seed}')\n",
    "X_train, X_test, y_train, y_test = train_test_split(features_df, targets_df[target_col], test_size=test_set_pct, random_state=seed)\n",
    "\n",
    "# gb = Ridge(alpha=1.0, normalize=True)\n",
    "gb = BaggingRegressor(base_estimator=Ridge(alpha=1.0, normalize=True), n_estimators=1000)\n",
    "#     gb = GradientBoostingRegressor(random_state=seed, max_depth=2)\n",
    "#     gb = RandomForestRegressor(random_state=seed)\n",
    "\n",
    "gb.fit(X_train, y_train)\n",
    "verbose = True\n",
    "preds = gb.predict(X_test)\n",
    "r2_score = gb.score(X_test, y_test)\n",
    "error = np.abs(y_test - preds)\n",
    "mean_hrs_error = error.mean()\n",
    "median_hrs_error = error.median()\n",
    "\n",
    "\n",
    "print(f'R^2 Score: {r2_score}')\n",
    "print(f'Mean absolute $ error: {mean_hrs_error}')\n",
    "print(f'Median absolute $ error: {median_hrs_error}')\n",
    "pred_misses, rule_misses = get_miss_ided(X_test, y_test, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train 2018\n",
    "# missed_advantage = []\n",
    "models = []\n",
    "lifts = []\n",
    "\n",
    "feature_cols = [c for c, v in cnt.items() if v >= 3]\n",
    "feature_cols = meta['features']\n",
    "mom_feats = [c for c in feature_cols if c in mom_feature_columns]# + ['p_mm']\n",
    "annual_feats = [c for c in feature_cols if c in annual_feature_columns]\n",
    "# print(i, ', '.join(feature_cols))\n",
    "\n",
    "#     lvl = '2. m'\n",
    "lvl = '1. h'\n",
    "df = data.loc[data.lvl_tgt == lvl]\n",
    "\n",
    "targets_df = df[['member_id', target_col]].groupby('member_id').first()\n",
    "\n",
    "features_df = features_annual(df, mom_feats)\n",
    "pre_annual = df.query(\"period < 0\")[annual_feats + ['member_id']].groupby('member_id').first()\n",
    "\n",
    "\n",
    "features_df = features_df.merge(pre_annual, left_index=True, right_index=True)\n",
    "features_df.fillna(0, inplace=True)\n",
    "\n",
    "\n",
    "# order features and targets by member id, make sure they line up perfectly\n",
    "features_df.sort_index(inplace=True)\n",
    "targets_df.sort_index(inplace=True)\n",
    "assert sum(targets_df.index - features_df.index) == 0\n",
    "\n",
    "for i in range(1000):\n",
    "\n",
    "    # train test split\n",
    "    # target_col = 'savings_tgt'\n",
    "    seed = random.randint(0, 1000)\n",
    "#     print(f'seed: {seed}')\n",
    "    X_train, X_test, y_train, y_test = train_test_split(features_df, targets_df[target_col], test_size=test_set_pct, random_state=seed)\n",
    "\n",
    "    gb = Ridge(alpha=1.0, normalize=True)\n",
    "#     gb = BaggingRegressor(base_estimator=Ridge(alpha=1.0, normalize=True), n_estimators=1000)\n",
    "    #     gb = GradientBoostingRegressor(random_state=seed, max_depth=2)\n",
    "    #     gb = RandomForestRegressor(random_state=seed)\n",
    "\n",
    "    gb.fit(X_train, y_train)\n",
    "    models.append(gb)\n",
    "    preds = gb.predict(X_test)\n",
    "    pred_misses, rule_misses = get_miss_ided(X_test, y_test, preds, verbose=False)\n",
    "    lifts.append(rule_misses - pred_misses)\n",
    "\n",
    "\n",
    "#     verbose = True\n",
    "#     r2_score = gb.score(X_test, y_test)\n",
    "#     error = np.abs(y_test - preds)\n",
    "#     mean_hrs_error = error.mean()\n",
    "#     median_hrs_error = error.median()\n",
    "\n",
    "\n",
    "#     print(f'R^2 Score: {r2_score}')\n",
    "#     print(f'Mean absolute $ error: {mean_hrs_error}')\n",
    "#     print(f'Median absolute $ error: {median_hrs_error}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_name = cb_utils.save_model(models, '2_h_savings_lr_1000_bag', {'name': '2_h_savings_lr_1000_bag', 'features': list(features_df.columns)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = '20200802_172434_2_h_savings_lr_10_bag'\n",
    "model, meta = cb_utils.load_model(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_cols = meta['features']\n",
    "\n",
    "mom_feats = [c for c in feature_cols if c in mom_feature_columns] \n",
    "annual_feats = [c for c in feature_cols if c in annual_feature_columns]\n",
    "\n",
    "lvl = '1. h'\n",
    "df = mab2.loc[data.lvl_tgt == lvl]\n",
    "\n",
    "targets_df = df[['member_id', target_col]].groupby('member_id').first()\n",
    "\n",
    "features_df = features_annual(df, mom_feats)\n",
    "pre_annual = df.query(\"period < 0\")[annual_feats + ['member_id']].groupby('member_id').first()\n",
    "\n",
    "\n",
    "features_df = features_df.merge(pre_annual, left_index=True, right_index=True)\n",
    "features_df.fillna(0, inplace=True)\n",
    "\n",
    "\n",
    "# order features and targets by member id, make sure they line up perfectly\n",
    "features_df.sort_index(inplace=True)\n",
    "targets_df.sort_index(inplace=True)\n",
    "assert sum(targets_df.index - features_df.index) == 0\n",
    "\n",
    "# train test split\n",
    "# target_col = 'savings_tgt'\n",
    "seed = random.randint(0, 1000)\n",
    "print(f'seed: {seed}')\n",
    "# X_train, X_test, y_train, y_test = train_test_split(features_df, targets_df[target_col], test_size=test_set_pct, random_state=seed)\n",
    "\n",
    "# gb = Ridge(alpha=1.0, normalize=True)\n",
    "# gb = BaggingRegressor(base_estimator=Ridge(alpha=1.0, normalize=True), n_estimators=10, random_state=0)\n",
    "#     gb = GradientBoostingRegressor(random_state=seed, max_depth=2)\n",
    "#     gb = RandomForestRegressor(random_state=seed)\n",
    "scores = [model.predict(features_df) for model in models]\n",
    "preds = np.mean(scores, axis=0)\n",
    "# gb = model\n",
    "\n",
    "# r2_score = gb.score(features_df, targets_df[target_col])\n",
    "# preds = gb.predict(features_df)\n",
    "error = np.abs(targets_df[target_col] - preds)\n",
    "mean_hrs_error = error.mean()\n",
    "median_hrs_error = error.median()\n",
    "\n",
    "\n",
    "# print(f'R^2 Score: {r2_score}')\n",
    "print(f'Mean absolute $ error: {mean_hrs_error}')\n",
    "print(f'Median absolute $ error: {median_hrs_error}')\n",
    "pred_misses, rule_misses = get_miss_ided(features_df, targets_df[target_col], preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = features_df.assign(pred=preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cb_utils.save_scores(result, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raise Exception(\"Stop here, Old code below\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = data.loc[data.lvl_tgt == '1. h']\n",
    "\n",
    "targets_df = df[['member_id', target_col]].groupby('member_id').first()\n",
    "targets_df.fillna(0, inplace=True)\n",
    "\n",
    "df = df.fillna(0)\n",
    "features_df = features_annual(df, feature_columns)\n",
    "model = train_and_test(features_df, targets_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model.predict(features_df)\n",
    "top_500_preds = features_df.assign(pred=preds).sort_values('pred', ascending=False).iloc[:500][['pred']]\n",
    "id_pop = data.loc[(data.lvl_tgt == '1. h')]\n",
    "# id_pop = data.loc[(data.lvl_tgt == lvl) & (data.period > 0)]\n",
    "id_pop = id_pop.set_index('member_id')\n",
    "id_pop = id_pop.merge(top_500_preds, left_index=True, right_index=True) \n",
    "id_pop = id_pop.merge(targets_df, left_index=True, right_index=True) \n",
    "id_pop = id_pop.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_pop.head()\n",
    "# features_df.assign(pred=preds)[['pred']].to_csv('../outputs/h_preds.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tcs = [c for c in features_df.columns if c[-3:] == '_tc'] + ['tc']\n",
    "tcs = [c for c in tcs if len(c) < 8 or c[:5] != 'hcbs_']\n",
    "\n",
    "g = sns.relplot(\n",
    "    x=\"period\",\n",
    "    y=\"value\",\n",
    "    hue=\"variable\",\n",
    "    kind=\"line\",\n",
    "    data=id_pop.melt(id_vars=['period'], value_vars=tcs),\n",
    "    height=12,\n",
    "    aspect=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tune hyperparameters: didn't see much benifit, takes about 30 minutes to run\n",
    "\n",
    "# lvl  = '1. h'\n",
    "# df = data.loc[data.lvl_tgt == lvl]\n",
    "# df = df.fillna(0)\n",
    "\n",
    "# targets_df = df[['member_id', target_col]].groupby('member_id').first()\n",
    "# feats_df = features_annual(df, feature_columns)\n",
    "\n",
    "# feats_df.sort_index(inplace=True)\n",
    "# targets_df.sort_index(inplace=True)\n",
    "# assert sum(targets_df.index - feats_df.index) == 0\n",
    "\n",
    "# # train test split\n",
    "# target_col = 'savings_tgt'\n",
    "# X_train, X_test, y_train, y_test = train_test_split(feats_df, targets_df[target_col], test_size=test_set_pct, random_state=seed)\n",
    "\n",
    "# gb = GradientBoostingRegressor(random_state=seed)\n",
    "\n",
    "# grid = {\n",
    "#     'learning_rate': [0.001, 0.01, 0.1, 0.2],\n",
    "#     'n_estimators': [10, 100, 500, 1000],\n",
    "#     'max_depth': [2, 3, 4, 5, 10],\n",
    "#     'min_samples_leaf': [1, 2, 3, 4, 5],\n",
    "# }\n",
    "\n",
    "# clf = GridSearchCV(gb, grid, n_jobs=os.cpu_count())\n",
    "\n",
    "# search = clf.fit(X_train, y_train)\n",
    "\n",
    "# cv_res = pd.DataFrame(search.cv_results_)\n",
    "# cv_res.sort_values('rank_test_score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_name = cb_utils.save_model(model, '1_xgb_cat_savings', {'name': '1_xgb_cat_savings', 'features': list(features_df.columns)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model trained on mab 5\n",
    "model_name = '20200731_153512_1_xgb_cat_savings'\n",
    "model, meta = cb_utils.load_model(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cb_utils.save_scores(final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test on a different population\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets_df = mab6[['member_id', target_col]].groupby('member_id').first()\n",
    "targets_df.fillna(0, inplace=True)\n",
    "\n",
    "mab6 = mab6.fillna(0)\n",
    "features_df = features_annual(mab6, feature_columns)\n",
    "features_df.sort_index(inplace=True)\n",
    "targets_df.sort_index(inplace=True)\n",
    "\n",
    "\n",
    "preds = model.predict(features_df)\n",
    "r2_score = model.score(features_df, targets_df[target_col])\n",
    "\n",
    "error = np.abs(targets_df[target_col] - preds)\n",
    "mean_hrs_error = error.mean()\n",
    "median_hrs_error = error.median()\n",
    "\n",
    "print('Testing MAB 6 data on model trained with mab 5')\n",
    "print(f'R^2 Score: {r2_score}')\n",
    "print(f'Mean absolute $ error: {mean_hrs_error}')\n",
    "print(f'Median absolute $ error: {median_hrs_error}')\n",
    "\n",
    "fig, ax = plt.subplots(nrows=1, figsize=(20,10))\n",
    "ax.scatter(preds, targets_df[target_col])\n",
    "ax.set_xlabel('preds')\n",
    "ax.set_ylabel('actual');\n",
    "ax.set_title(f'Predicted vs actual savings')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# try training on early set \n",
    "query = \"SELECT * FROM cb.vw_mab_training_data WHERE mab_id = 6;\"\n",
    "mab6 = cb_utils.sql_query_to_df(query, use_cache=use_cache)\n",
    "\n",
    "df = mab6.loc[data.lvl_tgt == '1. h']\n",
    "\n",
    "targets_df = df[['member_id', target_col]].groupby('member_id').first()\n",
    "targets_df.fillna(0, inplace=True)\n",
    "\n",
    "df = df.fillna(0)\n",
    "features_df = features_annual(df, feature_columns)\n",
    "model = train_and_test(features_df, targets_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
