{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "\n",
    "sys.path.append('../src')\n",
    "import cb_utils\n",
    "\n",
    "sns.set(style=\"darkgrid\")\n",
    "pd.options.display.max_columns = 500\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# configuration\n",
    "scoring_run_id = 1\n",
    "use_cache = True\n",
    "seed = 0\n",
    "test_set_pct = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "query = \"SELECT * FROM cb.vw_mab_training_data WHERE mab_id = 5;\"\n",
    "data = cb_utils.sql_query_to_df(query, use_cache=use_cache)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# limit to single assumption level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_columns = [\n",
    "    'lob_1_days'\n",
    "  , 'lob_2_days'\n",
    "  , 'lob_3_days'\n",
    "  , 'grp_1_days'\n",
    "  , 'grp_2_days'\n",
    "  , 'grp_3_days'\n",
    "  , 'grp_5_days'\n",
    "  , 'grp_6_days'\n",
    "  , 'grp_7_days'\n",
    "  , 'grp_8_days'\n",
    "  , 'unaligned_days'\n",
    "#   , 'is_unaligned'\n",
    "  , 'tc'\n",
    "  , 'hcbs_tc'\n",
    "  , 'icf_tc'\n",
    "  , 'ip_tc'\n",
    "  , 'rx_tc'\n",
    "  , 'ed_tc'\n",
    "  , 'snf_tc'\n",
    "  , 'out_tc'\n",
    "  , 'pro_tc'\n",
    "  , 'spfac_tc'\n",
    "  , 'amb_tc'\n",
    "  , 'hh_tc'\n",
    "  , 'hosp_tc'\n",
    "  , 'oth_tc'\n",
    "  , 'p_mm'\n",
    "  , 'mm'\n",
    "  , 'hcbs_respite_tc'\n",
    "  , 'hcbs_fam_care_stip_tc'\n",
    "  , 'hcbs_com_trans_tc'\n",
    "  , 'hcbs_educ_train_tc'\n",
    "  , 'hcbs_com_liv_fam_tc'\n",
    "  , 'hcbs_com_liv_tc'\n",
    "  , 'hcbs_attend_care_tc'\n",
    "  , 'hcbs_com_trans_waiv_tc'\n",
    "  , 'hcbs_home_meal_tc'\n",
    "  , 'hcbs_pers_care_tc'\n",
    "  , 'hcbs_ther_behav_tc'\n",
    "  , 'hcbs_unsk_respite_tc'\n",
    "  , 'hcbs_waiv_svc_tc'\n",
    "  , 'ddos'\n",
    "  , 'hcbs_ddos'\n",
    "  , 'icf_ddos'\n",
    "  , 'ip_ddos'\n",
    "  , 'rx_ddos'\n",
    "  , 'ed_ddos'\n",
    "  , 'snf_ddos'\n",
    "  , 'out_ddos'\n",
    "  , 'pro_ddos'\n",
    "  , 'spfac_ddos'\n",
    "  , 'amb_ddos'\n",
    "  , 'hh_ddos'\n",
    "  , 'hosp_ddos'\n",
    "  , 'oth_ddos'\n",
    "  , 'pcp_ddos'\n",
    "  , 'pulmonar_ddos'\n",
    "  , 'cancer_ddos'\n",
    "  , 'ckd_ddos'\n",
    "  , 'esrd_ddos'\n",
    "  , 'hyperlipid_ddos'\n",
    "  , 'diab_ddos'\n",
    "  , 'alzh_ddos'\n",
    "  , 'dementia_ddos'\n",
    "  , 'stroke_ddos'\n",
    "  , 'hypertension_ddos'\n",
    "  , 'fall_ddos'\n",
    "  , 'transplant_ddos'\n",
    "  , 'liver_ddos'\n",
    "  , 'hippfract_ddos'\n",
    "  , 'depression_ddos'\n",
    "  , 'psychosis_ddos'\n",
    "  , 'drug_ddos'\n",
    "  , 'alcohol_ddos'\n",
    "  , 'paralysis_ddos'\n",
    "]\n",
    "target_col = 'savings_tgt'\n",
    "len(feature_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try agg features at year and half year level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fully broken out month over month features\n",
    "def features_mom(df, cols):\n",
    "#     print('building month over month features')\n",
    "    df = df.fillna(0)\n",
    "    pre = df.query(\"period < 0\")\n",
    "    pre= pre.pivot(index='member_id', columns='period', values=cols)\n",
    "    pre.columns = [f'{period}-{name}' for (name, period) in pre.columns]\n",
    "    return pre.fillna(0)\n",
    "features_mom.name = 'MOM'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# agg semi yearly_features\n",
    "def features_semi_annual(df, cols):\n",
    "#     print('building semi annual features')\n",
    "    df = df.fillna(0)\n",
    "    pre = df.query(\"period < 0\")\n",
    "    h1 = pre.query('period < -6').groupby('member_id')\n",
    "    h2 = pre.query('period >= -6').groupby('member_id')\n",
    "\n",
    "    h1 = h1[cols].sum()\n",
    "    h2 = h2[cols].sum()\n",
    "\n",
    "    features_h1 = np.divide(h1[cols],  h1[['p_mm']])\n",
    "    features_h2 = np.divide(h2[cols],  h2[['p_mm']])\n",
    "    res = features_h2.merge(features_h1, left_index=True, right_index=True, suffixes=('_h2', '_h1'))\n",
    "    return res.fillna(0)\n",
    "features_semi_annual.name = 'Semi Annual'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# agg yearly_features\n",
    "def features_annual(df, cols):\n",
    "#     print('building annual features')\n",
    "    df = df.fillna(0)\n",
    "    pre = df.query(\"period < 0\").groupby('member_id')\n",
    "    pre_sums = pre[cols].sum()\n",
    "    res = np.divide(pre_sums[cols],  pre_sums[['p_mm']])\n",
    "    return res.fillna(0)\n",
    "features_annual.name = 'Annual'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_feature_importance(regr, cols, max_cols=20):\n",
    "    print('Feature Importance')\n",
    "    i = 0\n",
    "    for imp, feat in sorted([(b, a) for a, b in zip(cols, regr.feature_importances_)], reverse=True):\n",
    "        if imp > 0.001:\n",
    "            print('%0.3f: %s' % (imp, feat))\n",
    "            i += 1\n",
    "        if i > max_cols:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_test(feats_df, targets_df):\n",
    "    # order features and targets by member id, make sure they line up perfectly\n",
    "    feats_df.sort_index(inplace=True)\n",
    "    targets_df.sort_index(inplace=True)\n",
    "    assert sum(targets_df.index - feats_df.index) == 0\n",
    "\n",
    "    # train test split\n",
    "    target_col = 'savings_tgt'\n",
    "    X_train, X_test, y_train, y_test = train_test_split(feats_df, targets_df[target_col], test_size=test_set_pct, random_state=seed)\n",
    "\n",
    "    gb = GradientBoostingRegressor(random_state=seed)\n",
    "#     gb = RandomForestRegressor(random_state=seed)\n",
    "\n",
    "    gb.fit(X_train, y_train)\n",
    "    verbose = True\n",
    "    preds = gb.predict(X_test)\n",
    "    r2_score = gb.score(X_test, y_test)\n",
    "    error = np.abs(y_test - preds)\n",
    "    mean_hrs_error = error.mean()\n",
    "    median_hrs_error = error.median()\n",
    "    \n",
    "\n",
    "    print(f'R^2 Score: {r2_score}')\n",
    "    print(f'Mean absolute $ error: {mean_hrs_error}')\n",
    "    print(f'Median absolute $ error: {median_hrs_error}')\n",
    "    print_feature_importance(gb, features_df.columns)\n",
    "\n",
    "    if verbose:\n",
    "        fig, ax = plt.subplots(nrows=1, figsize=(20,10))\n",
    "        ax.scatter(preds, y_test)\n",
    "        ax.set_xlabel('preds')\n",
    "        ax.set_ylabel('actual');\n",
    "        ax.set_title(f'Predicted vs actual savings')\n",
    "        plt.show()\n",
    "    \n",
    "    return gb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_level_feature_space = False\n",
    "if search_level_feature_space:\n",
    "    levels = ('1. h', '2. m', '3. l')\n",
    "    feature_funcs = (features_mom, features_semi_annual, features_annual)\n",
    "    for lvl in levels:\n",
    "        df = data.loc[data.lvl_tgt == lvl]\n",
    "\n",
    "        targets_df = df[['member_id', target_col]].groupby('member_id').first()\n",
    "        targets_df.fillna(0, inplace=True)\n",
    "\n",
    "        for feat_func in feature_funcs: \n",
    "            print('Level: ', lvl)\n",
    "            print('Features: ', feat_func.name)\n",
    "            df = df.fillna(0)\n",
    "            features_df = feat_func(df, feature_columns)\n",
    "            model = train_and_test(features_df, targets_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = data.loc[data.lvl_tgt == '1. h']\n",
    "\n",
    "targets_df = df[['member_id', target_col]].groupby('member_id').first()\n",
    "targets_df.fillna(0, inplace=True)\n",
    "\n",
    "df = df.fillna(0)\n",
    "features_df = features_annual(df, feature_columns)\n",
    "model = train_and_test(features_df, targets_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model.predict(features_df)\n",
    "top_500_preds = features_df.assign(pred=preds).sort_values('pred', ascending=False).iloc[:500][['pred']]\n",
    "id_pop = data.loc[(data.lvl_tgt == '1. h')]\n",
    "# id_pop = data.loc[(data.lvl_tgt == lvl) & (data.period > 0)]\n",
    "id_pop = id_pop.set_index('member_id')\n",
    "id_pop = id_pop.merge(top_500_preds, left_index=True, right_index=True) \n",
    "id_pop = id_pop.merge(targets_df, left_index=True, right_index=True) \n",
    "id_pop = id_pop.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_pop.head()\n",
    "# features_df.assign(pred=preds)[['pred']].to_csv('../outputs/h_preds.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tcs = [c for c in features_df.columns if c[-3:] == '_tc'] + ['tc']\n",
    "tcs = [c for c in tcs if len(c) < 8 or c[:5] != 'hcbs_']\n",
    "\n",
    "g = sns.relplot(\n",
    "    x=\"period\",\n",
    "    y=\"value\",\n",
    "    hue=\"variable\",\n",
    "    kind=\"line\",\n",
    "    data=id_pop.melt(id_vars=['period'], value_vars=tcs),\n",
    "    height=12,\n",
    "    aspect=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tune hyperparameters: didn't see much benifit, takes about 30 minutes to run\n",
    "\n",
    "# lvl  = '1. h'\n",
    "# df = data.loc[data.lvl_tgt == lvl]\n",
    "# df = df.fillna(0)\n",
    "\n",
    "# targets_df = df[['member_id', target_col]].groupby('member_id').first()\n",
    "# feats_df = features_annual(df, feature_columns)\n",
    "\n",
    "# feats_df.sort_index(inplace=True)\n",
    "# targets_df.sort_index(inplace=True)\n",
    "# assert sum(targets_df.index - feats_df.index) == 0\n",
    "\n",
    "# # train test split\n",
    "# target_col = 'savings_tgt'\n",
    "# X_train, X_test, y_train, y_test = train_test_split(feats_df, targets_df[target_col], test_size=test_set_pct, random_state=seed)\n",
    "\n",
    "# gb = GradientBoostingRegressor(random_state=seed)\n",
    "\n",
    "# grid = {\n",
    "#     'learning_rate': [0.001, 0.01, 0.1, 0.2],\n",
    "#     'n_estimators': [10, 100, 500, 1000],\n",
    "#     'max_depth': [2, 3, 4, 5, 10],\n",
    "#     'min_samples_leaf': [1, 2, 3, 4, 5],\n",
    "# }\n",
    "\n",
    "# clf = GridSearchCV(gb, grid, n_jobs=os.cpu_count())\n",
    "\n",
    "# search = clf.fit(X_train, y_train)\n",
    "\n",
    "# cv_res = pd.DataFrame(search.cv_results_)\n",
    "# cv_res.sort_values('rank_test_score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_name = cb_utils.save_model(model, '1_xgb_cat_savings', {'name': '1_xgb_cat_savings', 'features': list(features_df.columns)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model trained on mab 5\n",
    "model_name = '20200731_153512_1_xgb_cat_savings'\n",
    "model, meta = cb_utils.load_model(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cb_utils.save_scores(final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test on a different population\n",
    "query = \"SELECT * FROM cb.vw_mab_training_data WHERE mab_id = 6;\"\n",
    "mab6 = cb_utils.sql_query_to_df(query, use_cache=use_cache)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets_df = mab6[['member_id', target_col]].groupby('member_id').first()\n",
    "targets_df.fillna(0, inplace=True)\n",
    "\n",
    "mab6 = mab6.fillna(0)\n",
    "features_df = features_annual(mab6, feature_columns)\n",
    "features_df.sort_index(inplace=True)\n",
    "targets_df.sort_index(inplace=True)\n",
    "\n",
    "\n",
    "preds = model.predict(features_df)\n",
    "r2_score = model.score(features_df, targets_df[target_col])\n",
    "\n",
    "error = np.abs(targets_df[target_col] - preds)\n",
    "mean_hrs_error = error.mean()\n",
    "median_hrs_error = error.median()\n",
    "\n",
    "print('Testing MAB 6 data on model trained with mab 5')\n",
    "print(f'R^2 Score: {r2_score}')\n",
    "print(f'Mean absolute $ error: {mean_hrs_error}')\n",
    "print(f'Median absolute $ error: {median_hrs_error}')\n",
    "\n",
    "fig, ax = plt.subplots(nrows=1, figsize=(20,10))\n",
    "ax.scatter(preds, targets_df[target_col])\n",
    "ax.set_xlabel('preds')\n",
    "ax.set_ylabel('actual');\n",
    "ax.set_title(f'Predicted vs actual savings')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# try training on early set \n",
    "query = \"SELECT * FROM cb.vw_mab_training_data WHERE mab_id = 6;\"\n",
    "mab6 = cb_utils.sql_query_to_df(query, use_cache=use_cache)\n",
    "\n",
    "df = mab6.loc[data.lvl_tgt == '1. h']\n",
    "\n",
    "targets_df = df[['member_id', target_col]].groupby('member_id').first()\n",
    "targets_df.fillna(0, inplace=True)\n",
    "\n",
    "df = df.fillna(0)\n",
    "features_df = features_annual(df, feature_columns)\n",
    "model = train_and_test(features_df, targets_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
