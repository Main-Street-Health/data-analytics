{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf6f6cac-9cbd-4571-b1d7-95dfa7d12bde",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import sys\n",
    "import collections\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import copy\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "sys.path.append('../src')\n",
    "import cb_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c45e5c44-994a-423b-9255-4cf5964527a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw = cb_utils.sql_query_to_df('SELECT * FROM junk.cui_ndc_hcc_dataset;')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84a4ef37-21d8-4489-bf53-bcf49df9c223",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = len(raw)\n",
    "n_samples "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66bf1931-feaa-4bb0-9617-0f511c56a506",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63649b94-e4b5-4cf9-9648-fdd07be832d5",
   "metadata": {},
   "source": [
    "### Create lookups for cui and hccs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a22c6b9-e1c6-4b78-bd52-fe06c38aa4c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "cuis = collections.Counter()\n",
    "for r in raw.rscuis:\n",
    "    cuis.update(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47f58613-45ec-469b-9607-dd18cf9d4f8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_cuis = len(cuis)\n",
    "n_cuis  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1368351-05a5-43a7-a3c4-ea7e95b3da50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# raw.categories.apply(lambda x: len(x) if x is not None else 0).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35208803-f788-4372-b675-e9a1537de3f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# raw.rscuis.apply(lambda x: len(x)).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d166ff11-a01b-4eb6-932a-8804cb7663f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# list(reversed(cuis.most_common(1000)))[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e0a87d5-3045-4167-9167-b284ea812928",
   "metadata": {},
   "outputs": [],
   "source": [
    "cui_lookup = {}\n",
    "for i, (cui, cnt) in enumerate(cuis.most_common()):\n",
    "    cui_lookup[i + 1] = cui"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70b84727-2e8b-4c88-826f-2c260ce3e318",
   "metadata": {},
   "outputs": [],
   "source": [
    "cui_idx_lookup = {v: k for k, v in cui_lookup.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ea37ad0-1ea0-4b3d-a5b8-5d46cd7dfe19",
   "metadata": {},
   "outputs": [],
   "source": [
    "hccs = collections.Counter()\n",
    "for r in raw.categories:\n",
    "    hccs.update(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d809baf-ad7c-4baf-89dd-ae25db31d1e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_hccs = len(hccs)\n",
    "n_hccs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "981c846d-8d39-470c-a555-de57669ba90c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hccs.most_common()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e38ac022-e6f2-4c8d-bd02-35a46c3fe9a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "hcc_lookup = {}\n",
    "for i, (hcc, cnt) in enumerate(hccs.most_common()):\n",
    "    hcc_lookup[i] = hcc\n",
    "hcc_idx_lookup = {v: k for k, v in hcc_lookup.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcdd2874-c878-4733-8ef6-ad7cc71d7ce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_cuis = 104\n",
    "X = np.zeros((n_samples, max_cuis))\n",
    "Y = np.zeros((n_samples, n_hccs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a0fc89b-7ca4-4986-9616-a7e20b253454",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cui_idx(a): \n",
    "    return cui_idx_lookup[a]\n",
    "\n",
    "for i, r in raw.iterrows():\n",
    "    sorted_cuis = list(r.rscuis)\n",
    "    sorted_cuis.sort(key=get_cui_idx)\n",
    "    sorted_cuis = sorted_cuis[:max_cuis]\n",
    "    for c, cui in enumerate(sorted_cuis):\n",
    "        X[i, c] = cui_idx_lookup[cui]\n",
    "    \n",
    "    if r.categories is not None:\n",
    "        for hcc in r.categories:\n",
    "            Y[i, hcc_idx_lookup[hcc]] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ea311e6-336b-41a4-b351-63c1ecd6b8f0",
   "metadata": {},
   "source": [
    "### Train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c491ac7-efad-49f1-9893-3551d51303ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "947cd8ae-43c3-4133-9e3e-68e5f3560fc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "151a1f7a-caf8-48b7-97ee-b56e576aeee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = torch.tensor(X_train, dtype=torch.int, device=device)\n",
    "X_test = torch.tensor(X_test, dtype=torch.int, device=device)\n",
    "X_val = torch.tensor(X_val, dtype=torch.int, device=device)\n",
    "y_train = torch.tensor(y_train, dtype=torch.float, device=device)\n",
    "y_test = torch.tensor(y_test, dtype=torch.float, device=device)\n",
    "y_val = torch.tensor(y_val, dtype=torch.float, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7f410ec-5126-4ca6-b814-c47805735a00",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e6970048-be6b-4e19-b7bb-53d9e56c6482",
   "metadata": {},
   "source": [
    "### MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb57fd5e-141a-4f9b-820d-ced9b378f41d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EmbMLP(nn.Module):\n",
    "    def __init__(self, embedding_dim=600, dropout=0.01, device=device):\n",
    "        super(EmbMLP, self).__init__()\n",
    "        self.emb_dim = embedding_dim\n",
    "        self.emb = nn.Embedding(n_cuis + 1, embedding_dim=embedding_dim, padding_idx=0)\n",
    "        \n",
    "        self.mlp_model = nn.Sequential(\n",
    "            \n",
    "            nn.Linear(embedding_dim, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(32),\n",
    "            nn.Dropout(dropout),\n",
    "            \n",
    "            nn.Linear(32, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.Dropout(dropout),\n",
    "            \n",
    "            nn.Linear(128, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.Dropout(dropout),\n",
    "            \n",
    "            nn.Linear(256, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.Dropout(dropout),\n",
    "            \n",
    "            nn.Linear(128, n_hccs)\n",
    "        )\n",
    "        if device == 'cuda':\n",
    "            self.cuda()\n",
    "    \n",
    "    def forward(self, inputs):\n",
    "        e = self.emb(inputs)\n",
    "        emb = torch.sum(e, axis=1)\n",
    "        return self.mlp_model(emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e664d91-6872-411e-a8be-70f5c5d26a4a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31a6c28c-b011-4157-9ffd-e1ae090b0188",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AverageMeter():\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "\n",
    "\n",
    "def train_loop(model, X_train, y_train, batch_size):\n",
    "    losses = AverageMeter()\n",
    "    for i in range(0, X_train.shape[0] // batch_size):\n",
    "        batch_start = i * batch_size\n",
    "        batch_end = (i + 1) * batch_size\n",
    "\n",
    "        x = X_train[batch_start: batch_end]\n",
    "        y = y_train[batch_start: batch_end]\n",
    "        \n",
    "        output = model(x)\n",
    "        loss = criterion(output, y)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        l = loss.item()\n",
    "        losses.update(l, output.shape[0])\n",
    "        \n",
    "    print('Loss: {:.3f}'.format(l))\n",
    "            \n",
    "    return losses.avg\n",
    "        \n",
    "def validation_loop(model, X_val, y_val, batch_size):\n",
    "    losses = AverageMeter()\n",
    "    for i in range(0, X_val.shape[0] // batch_size):\n",
    "        batch_start = i * batch_size\n",
    "        batch_end = (i + 1) * batch_size\n",
    "\n",
    "        x = X_val[batch_start: batch_end]\n",
    "        y = y_val[batch_start: batch_end]\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            output = model(x)\n",
    "            loss = criterion(output, y)\n",
    "            l = loss.item()\n",
    "            losses.update(l, output.shape[0])\n",
    "    print('val Loss: {:.3f}'.format(losses.avg))\n",
    "    return losses.avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59f12423-78cd-41d5-a404-eea106084158",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_model = EmbMLP(device=device, embedding_dim=600, dropout=0.1)\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.Adam(mlp_model.parameters())\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "best_val_loss = np.inf\n",
    "best_val_epoch = 0\n",
    "best_model = copy.deepcopy(mlp_model)\n",
    "\n",
    "epoch = 0\n",
    "\n",
    "while epoch < 100:\n",
    "    epoch += 1\n",
    "    print('EPOCH: ', epoch)\n",
    "    train_loss = train_loop(mlp_model, X_train, y_train, 256)\n",
    "    val_loss = validation_loop(mlp_model, X_val, y_val, 256)\n",
    "    train_losses.append(train_loss)\n",
    "    val_losses.append(val_loss)\n",
    "    \n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        best_val_epoch = epoch\n",
    "        best_model = copy.deepcopy(mlp_model)\n",
    "        print('new best val Loss: {:.3f}'.format(best_val_loss))\n",
    "    elif epoch - best_val_epoch > 10:\n",
    "        print('Stopping early no improvement since epoch', best_val_epoch)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af0ef4dc-93c0-4e0e-90d6-825233a61641",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()  # Create a figure and an axes.\n",
    "ax.plot(train_losses, label='Train')  # Plot some data on the axes.\n",
    "ax.plot(val_losses, label='Val')\n",
    "ax.legend()\n",
    "# .111 best "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78803a25-0299-462e-b4ef-fc385cca22a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_results(model, X, labels, thresholds=None):\n",
    "    if thresholds is None:\n",
    "        thresholds = np.arange(0.1, 1, .1)\n",
    "\n",
    "    results = []\n",
    "        \n",
    "    for pos_threshold in thresholds:\n",
    "        preds = torch.sigmoid(model(X))\n",
    "        pred_labels = torch.zeros_like(preds)\n",
    "        pred_labels[preds > pos_threshold] = 1\n",
    "\n",
    "        tp = torch.sum(pred_labels + labels == 2, axis=1, dtype=torch.float)\n",
    "        tn = torch.sum(pred_labels + labels == 0, axis=1, dtype=torch.float)\n",
    "        fp = torch.sum(pred_labels - labels == 1, axis=1, dtype=torch.float)\n",
    "        fn = torch.sum(pred_labels - labels == -1, axis=1, dtype=torch.float)\n",
    "\n",
    "        acc = (tp + tn) / (tp + tn + fp + fn) \n",
    "\n",
    "        recall = tp / (tp + fn)\n",
    "        # recall[recall.isnan()] = 1\n",
    "        results.append({\n",
    "            'threshold': pos_threshold,\n",
    "            'avg_recall': recall[~recall.isnan()].mean().item(),\n",
    "            'avg_acc': acc.mean().item(),\n",
    "            'tp_avg': tp.mean().item(),\n",
    "            'tp_max': tp.max().item(),\n",
    "            'tp_median': tp.median().item(),\n",
    "            'tp_std': tp.std().item(),\n",
    "            'fp_avg': fp.mean().item(),\n",
    "            'fp_max': fp.max().item(),\n",
    "            'fp_median': fp.median().item(),\n",
    "            'fp_std': fp.std().item(),\n",
    "            'tn_avg': tn.mean().item(),\n",
    "            'tn_max': tn.max().item(),\n",
    "            'tn_median': tn.median().item(),\n",
    "            'tn_std': tn.std().item(),\n",
    "            'fn_avg': fn.mean().item(),\n",
    "            'fn_max': fn.max().item(),\n",
    "            'fn_median': fn.median().item(),\n",
    "            'fn_std': fn.std().item(),\n",
    "        })\n",
    "    return pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7338605-0c73-4bd8-a27d-69f3d5615c8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = build_results(best_model, X_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37f9fddc-dc18-4fa9-862e-6f55bf948682",
   "metadata": {},
   "outputs": [],
   "source": [
    "results.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f93a291b-1541-4517-a24a-b5c9538019cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "results.columns.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4602a4cc-8179-4a00-92da-590bb80361ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "tall = results.melt(id_vars=['threshold'],\n",
    "             value_vars=[\n",
    "                 'avg_recall',\n",
    "                 'avg_acc',\n",
    "                 'tp_avg',\n",
    "                 'tp_max',\n",
    "                 'tp_median',\n",
    "                 'tp_std',\n",
    "                 'fp_avg',\n",
    "                 'fp_max',\n",
    "                 'fp_median',\n",
    "                 'fp_std',\n",
    "                 'tn_avg',\n",
    "                 'tn_max',\n",
    "                 'tn_median',\n",
    "                 'tn_std',\n",
    "                 'fn_avg',\n",
    "                 'fn_max',\n",
    "                 'fn_median',\n",
    "                 'fn_std'\n",
    "             ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f43d6b4-e22e-43fb-b310-9e778bc82adc",
   "metadata": {},
   "outputs": [],
   "source": [
    "tall.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3775c17-36bb-42c6-8cd3-7e3b443c9944",
   "metadata": {},
   "outputs": [],
   "source": [
    "tall = tall.assign(grp=tall.variable.str.split('_').map(lambda x: x[0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a9d3835-3f81-49dc-9f8f-d71e51d61c27",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = tall.loc[tall.variable.isin(['tp_avg', 'fp_avg', 'fn_avg'])]\n",
    "sns.relplot(data=df, x='threshold', y='value', hue='variable',  kind='line')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4b89a6a-ab06-4577-a455-3e9b65b744b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = tall.loc[tall.variable.isin(['tp_median', 'fp_median', 'fn_median'])]\n",
    "sns.relplot(data=df, x='threshold', y='value', hue='variable',  kind='line')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c58b127-315c-40ad-b014-544715d2cf2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = tall.loc[tall.variable.isin(['avg_acc'])]\n",
    "sns.relplot(data=df, x='threshold', y='value', hue='variable',  kind='line')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e3f69af-3690-4850-929a-34846e9718fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = tall.loc[tall.variable.isin(['avg_recall'])]\n",
    "sns.relplot(data=df, x='threshold', y='value', hue='variable',  kind='line')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b3816bc-8cc9-4c27-9f4d-10f4e6a963cf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
