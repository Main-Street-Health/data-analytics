{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata (current_repodata.json): done\n",
      "Solving environment: | \n",
      "The environment is inconsistent, please check the package plan carefully\n",
      "The following packages are causing the inconsistency:\n",
      "\n",
      "  - defaults/linux-64::jpeg==9b=h024ee3a_2\n",
      "  - defaults/linux-64::libtiff==4.1.0=h2733197_1\n",
      "  - defaults/linux-64::lcms2==2.11=h396b838_0\n",
      "  - defaults/linux-64::libwebp==1.0.1=h8e7db2f_0\n",
      "  - defaults/linux-64::openjpeg==2.3.0=h05c96fa_1\n",
      "  - defaults/linux-64::cairo==1.14.12=h8948797_3\n",
      "  - defaults/linux-64::qt==5.9.7=h5867ecd_1\n",
      "  - defaults/noarch::black==19.10b0=py_0\n",
      "  - defaults/linux-64::harfbuzz==2.4.0=hca77d97_1\n",
      "  - defaults/linux-64::mkl-service==2.3.0=py37he8ac12f_0\n",
      "  - defaults/linux-64::pyqt==5.9.2=py37h05f1152_2\n",
      "  - defaults/linux-64::numpy-base==1.19.2=py37hfa32c7d_0\n",
      "  - defaults/linux-64::pango==1.45.3=hd140c19_0\n",
      "  - defaults/noarch::flask==1.1.2=pyhd3eb1b0_0\n",
      "  - defaults/linux-64::pyopenssl==19.1.0=py37_0\n",
      "  - defaults/linux-64::secretstorage==3.3.1=py37h06a4308_0\n",
      "  - defaults/linux-64::keyring==22.0.1=py37h06a4308_0\n",
      "  - defaults/linux-64::pytest==6.2.2=py37h06a4308_2\n",
      "  - defaults/noarch::pyls-black==0.4.6=hd3eb1b0_0\n",
      "  - defaults/linux-64::anaconda-client==1.7.2=py37_0\n",
      "  - defaults/linux-64::conda==4.8.4=py37_0\n",
      "  - defaults/linux-64::nbconvert==6.0.7=py37_0\n",
      "  - defaults/noarch::qtconsole==5.0.2=pyhd3eb1b0_0\n",
      "  - defaults/noarch::sphinx==3.5.1=pyhd3eb1b0_0\n",
      "  - defaults/noarch::anaconda-project==0.9.1=pyhd3eb1b0_1\n",
      "  - defaults/noarch::numpydoc==1.1.0=pyhd3eb1b0_1\n",
      "  - defaults/linux-64::spyder==4.2.1=py37h06a4308_1\n",
      "  - defaults/linux-64::widgetsnbextension==3.5.1=py37_0\n",
      "  - defaults/noarch::ipywidgets==7.6.3=pyhd3eb1b0_1\n",
      "  - defaults/linux-64::jupyter==1.0.0=py37_7\n",
      "  - defaults/linux-64::bottleneck==1.3.2=py37heb32a55_1\n",
      "  - defaults/linux-64::h5py==2.10.0=py37h7918eee_0\n",
      "  - defaults/linux-64::imagecodecs==2021.1.11=py37h581e88b_1\n",
      "  - defaults/linux-64::matplotlib==3.3.4=py37h06a4308_0\n",
      "  - defaults/linux-64::matplotlib-base==3.3.4=py37h62a2d02_0\n",
      "  - defaults/linux-64::mkl_fft==1.2.1=py37h54f3939_0\n",
      "  - defaults/linux-64::mkl_random==1.1.1=py37h0573a6f_0\n",
      "  - defaults/linux-64::numpy==1.19.2=py37h54aff64_0\n",
      "  - defaults/noarch::imageio==2.9.0=py_0\n",
      "  - defaults/linux-64::numba==0.51.2=py37h04863e7_1\n",
      "  - defaults/linux-64::numexpr==2.7.2=py37hb2eb853_0\n",
      "  - defaults/linux-64::pandas==1.2.2=py37ha9443f7_0\n",
      "  - defaults/linux-64::pyerfa==1.7.2=py37h27cfd23_0\n",
      "  - defaults/linux-64::pywavelets==1.1.1=py37h7b6447c_2\n",
      "  - defaults/linux-64::scipy==1.6.1=py37h91f5cce_0\n",
      "  - defaults/noarch::tifffile==2021.1.14=pyhd3eb1b0_1\n",
      "  - defaults/linux-64::astropy==4.2=py37h27cfd23_0\n",
      "  - defaults/linux-64::bkcharts==0.2=py37_0\n",
      "  - defaults/noarch::dask==2021.2.0=pyhd3eb1b0_0\n",
      "  - defaults/linux-64::patsy==0.5.1=py37_0\n",
      "  - defaults/linux-64::pytables==3.6.1=py37h71ec239_0\n",
      "  - defaults/linux-64::scikit-image==0.17.2=py37hdf5156a_0\n",
      "  - defaults/linux-64::scikit-learn==0.23.2=py37h0573a6f_0\n",
      "  - defaults/noarch::seaborn==0.11.1=pyhd3eb1b0_0\n",
      "  - defaults/linux-64::statsmodels==0.12.2=py37h27cfd23_0\n",
      "  - defaults/linux-64::_anaconda_depends==2020.07=py37_0\n",
      "failed with repodata from current_repodata.json, will retry with next repodata source.\n",
      "Solving environment: failed with repodata from current_repodata.json, will retry with next repodata source.\n",
      "Collecting package metadata (repodata.json): done\n",
      "Solving environment: / \n",
      "The environment is inconsistent, please check the package plan carefully\n",
      "The following packages are causing the inconsistency:\n",
      "\n",
      "  - defaults/noarch::black==19.10b0=py_0\n",
      "  - defaults/noarch::flask==1.1.2=pyhd3eb1b0_0\n",
      "  - defaults/linux-64::pyopenssl==19.1.0=py37_0\n",
      "  - defaults/linux-64::secretstorage==3.3.1=py37h06a4308_0\n",
      "  - defaults/linux-64::keyring==22.0.1=py37h06a4308_0\n",
      "  - defaults/linux-64::pytest==6.2.2=py37h06a4308_2\n",
      "  - defaults/noarch::pyls-black==0.4.6=hd3eb1b0_0\n",
      "  - defaults/linux-64::anaconda-client==1.7.2=py37_0\n",
      "  - defaults/linux-64::conda==4.8.4=py37_0\n",
      "  - defaults/linux-64::nbconvert==6.0.7=py37_0\n",
      "  - defaults/noarch::sphinx==3.5.1=pyhd3eb1b0_0\n",
      "  - defaults/noarch::anaconda-project==0.9.1=pyhd3eb1b0_1\n",
      "  - defaults/noarch::numpydoc==1.1.0=pyhd3eb1b0_1\n",
      "  - defaults/linux-64::spyder==4.2.1=py37h06a4308_1\n",
      "  - defaults/linux-64::widgetsnbextension==3.5.1=py37_0\n",
      "  - defaults/noarch::ipywidgets==7.6.3=pyhd3eb1b0_1\n",
      "  - defaults/linux-64::jupyter==1.0.0=py37_7\n",
      "  - defaults/linux-64::matplotlib==3.3.4=py37h06a4308_0\n",
      "  - defaults/linux-64::matplotlib-base==3.3.4=py37h62a2d02_0\n",
      "  - defaults/noarch::imageio==2.9.0=py_0\n",
      "  - defaults/noarch::dask==2021.2.0=pyhd3eb1b0_0\n",
      "  - defaults/linux-64::scikit-image==0.17.2=py37hdf5156a_0\n",
      "  - defaults/noarch::seaborn==0.11.1=pyhd3eb1b0_0\n",
      "  - defaults/linux-64::_anaconda_depends==2020.07=py37_0\n",
      "done\n",
      "\n",
      "\n",
      "==> WARNING: A newer version of conda exists. <==\n",
      "  current version: 4.8.4\n",
      "  latest version: 4.11.0\n",
      "\n",
      "Please update conda by running\n",
      "\n",
      "    $ conda update -n base -c defaults conda\n",
      "\n",
      "\n",
      "\n",
      "## Package Plan ##\n",
      "\n",
      "  environment location: /home/ec2-user/anaconda3\n",
      "\n",
      "  added / updated specs:\n",
      "    - conda\n",
      "\n",
      "\n",
      "The following NEW packages will be INSTALLED:\n",
      "\n",
      "  anyio              pkgs/main/linux-64::anyio-3.5.0-py37h06a4308_0\n",
      "  babel              pkgs/main/noarch::babel-2.9.1-pyhd3eb1b0_0\n",
      "  bleach             pkgs/main/noarch::bleach-4.1.0-pyhd3eb1b0_0\n",
      "  bokeh              pkgs/main/linux-64::bokeh-2.4.2-py37h06a4308_0\n",
      "  charset-normalizer pkgs/main/noarch::charset-normalizer-2.0.4-pyhd3eb1b0_0\n",
      "  colorama           pkgs/main/noarch::colorama-0.4.4-pyhd3eb1b0_0\n",
      "  cryptography       pkgs/main/linux-64::cryptography-36.0.0-py37h9ce1e76_0\n",
      "  dataclasses        pkgs/main/noarch::dataclasses-0.8-pyh6d0b6a4_7\n",
      "  docutils           pkgs/main/linux-64::docutils-0.18.1-py37h06a4308_2\n",
      "  jupyter_server     pkgs/main/noarch::jupyter_server-1.13.5-pyhd3eb1b0_0\n",
      "  jupyterlab         pkgs/main/noarch::jupyterlab-3.2.9-pyhd3eb1b0_0\n",
      "  jupyterlab_server  pkgs/main/noarch::jupyterlab_server-2.10.3-pyhd3eb1b0_1\n",
      "  lxml               pkgs/main/linux-64::lxml-4.6.3-py37h9120a33_0\n",
      "  nbclassic          pkgs/main/noarch::nbclassic-0.3.5-pyhd3eb1b0_0\n",
      "  notebook           pkgs/main/linux-64::notebook-6.4.8-py37h06a4308_0\n",
      "  packaging          pkgs/main/noarch::packaging-21.3-pyhd3eb1b0_0\n",
      "  pillow             pkgs/main/linux-64::pillow-8.2.0-py37he98fc37_0\n",
      "  pip                pkgs/main/linux-64::pip-21.2.2-py37h06a4308_0\n",
      "  requests           pkgs/main/noarch::requests-2.27.1-pyhd3eb1b0_0\n",
      "  send2trash         pkgs/main/noarch::send2trash-1.8.0-pyhd3eb1b0_1\n",
      "  sniffio            pkgs/main/linux-64::sniffio-1.2.0-py37h06a4308_1\n",
      "  typing_extensions  pkgs/main/noarch::typing_extensions-3.10.0.2-pyh06a4308_0\n",
      "  urllib3            pkgs/main/noarch::urllib3-1.26.8-pyhd3eb1b0_0\n",
      "  websocket-client   pkgs/main/linux-64::websocket-client-0.58.0-py37h06a4308_4\n",
      "  werkzeug           pkgs/main/noarch::werkzeug-2.0.2-pyhd3eb1b0_0\n",
      "\n",
      "The following packages will be UPDATED:\n",
      "\n",
      "  ca-certificates    conda-forge::ca-certificates-2021.10.~ --> pkgs/main::ca-certificates-2021.10.26-h06a4308_2\n",
      "  certifi            conda-forge::certifi-2021.10.8-py37h8~ --> pkgs/main::certifi-2021.10.8-py37h06a4308_2\n",
      "  openssl            conda-forge::openssl-1.1.1k-h7f98852_0 --> pkgs/main::openssl-1.1.1m-h7f8727e_0\n",
      "\n",
      "The following packages will be SUPERSEDED by a higher-priority channel:\n",
      "\n",
      "  matplotlib-inline  conda-forge::matplotlib-inline-0.1.3-~ --> pkgs/main::matplotlib-inline-0.1.2-pyhd3eb1b0_2\n",
      "\n",
      "\n",
      "Preparing transaction: done\n",
      "Verifying transaction: failed\n",
      "\n",
      "RemoveError: 'requests' is a dependency of conda and cannot be removed from\n",
      "conda's operating environment.\n",
      "\n",
      "\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Collecting package metadata (current_repodata.json): done\n",
      "Solving environment: done\n",
      "\n",
      "\n",
      "==> WARNING: A newer version of conda exists. <==\n",
      "  current version: 4.8.4\n",
      "  latest version: 4.11.0\n",
      "\n",
      "Please update conda by running\n",
      "\n",
      "    $ conda update -n base -c defaults conda\n",
      "\n",
      "\n",
      "\n",
      "# All requested packages already installed.\n",
      "\n",
      "\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# %conda update -n base -c defaults conda\n",
    "# %conda install pymysql\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/psycopg2/__init__.py:144: UserWarning: The psycopg2 wheel package will be renamed from release 2.8; in order to keep installing from binary please use \"pip install psycopg2-binary\" instead. For details see: <http://initd.org/psycopg/docs/install.html#binary-install-from-pypi>.\n",
      "  \"\"\")\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import io\n",
    "import sys\n",
    "import time\n",
    "import random\n",
    "import warnings\n",
    "import collections\n",
    "from dateutil.relativedelta import relativedelta\n",
    "import boto3\n",
    "import sagemaker\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "import seaborn as sns\n",
    "from sklearn.experimental import enable_hist_gradient_boosting\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, BaggingRegressor, StackingRegressor, HistGradientBoostingRegressor \n",
    "from sklearn.linear_model import Ridge, Lasso, BayesianRidge, ElasticNet\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "sys.path.append('../src')\n",
    "import cb_utils\n",
    "\n",
    "sns.set(style=\"darkgrid\")\n",
    "pd.options.display.max_columns = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed: 91\n"
     ]
    }
   ],
   "source": [
    "# configuration\n",
    "use_cache = True\n",
    "seed = random.randint(0, 100)\n",
    "\n",
    "print(f'Seed: {seed}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "role = sagemaker.get_execution_role()\n",
    "bucket_name = 'cb-analytics-us-east-2-prd'\n",
    "prefix = 'sagemaker/'\n",
    "file_name = 'ip_features_all.parquet'\n",
    "# my_region = boto3.session.Session().region_name # set the region of the instance\n",
    "\n",
    "obj = boto3.Session().resource('s3').Bucket(bucket_name).Object(os.path.join(prefix, file_name)).get()\n",
    "ip_features_all = pd.read_parquet(io.BytesIO(obj['Body'].read()))\n",
    "ip_features_all.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ip_features_all.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mark good member periods\n",
    "\n",
    "eligible members on day of id and first day of post\n",
    "\n",
    "iterate from first month to total_months - pre + post_period, create pre/post for member if elg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_months = 12\n",
    "post_months = 6\n",
    "pre_post_months = pre_months + post_months"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "months = sorted(ip_features_all.eom.unique())\n",
    "n_months = len(months)\n",
    "last_valid_pre_start = n_months - pre_post_months # 42\n",
    "months[:3], months[-3:], n_months, last_valid_pre_start "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# create bool column flags to easily query what batches this can be in\n",
    "# pres = {f'pre_{i}': False for i, _ in enumerate(months) if i < last_valid_pre_start}\n",
    "# posts = {f'post_{i}': False for i, _ in enumerate(months) if i < last_valid_pre_start}\n",
    "flags = {f'{prefix}_{i}': False for prefix in ['pre', 'post', 'pre_post_elg'] for i in range(n_months) if i < last_valid_pre_start}\n",
    "ip_features_all = ip_features_all.assign(**flags);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ifa = ip_features_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assign bool flags for each potential period\n",
    "periods = []\n",
    "for i in tqdm(range(last_valid_pre_start)):\n",
    "    # Build date anchor points relative to start month\n",
    "    pre_start = months[i]\n",
    "    pre_end = months[i+11]\n",
    "    # id_date = pre_end + relativedelta(days=1)\n",
    "    \n",
    "    post_start = None\n",
    "    post_end = None\n",
    "    if i + 17 < n_months:\n",
    "        post_start = months[i+12]\n",
    "        post_end = months[i+17]\n",
    "        \n",
    "    periods.append([i, pre_start, pre_end, post_start, post_end])\n",
    "\n",
    "    # Determine elg members\n",
    "    pre_elg = ifa.loc[(ifa.eom == pre_end) & (ifa.is_cb_eligible)].member_id.unique()\n",
    "    post_elg = ifa.loc[(ifa.eom == post_start) & (ifa.is_cb_eligible)].member_id.unique()\n",
    "\n",
    "    pre_post_elg_mems = np.intersect1d(pre_elg, post_elg)\n",
    "\n",
    "    # Flag elg members for period i\n",
    "    ifa.loc[(ifa.eom >= pre_start) & (ifa.eom <= pre_end) & (ifa.member_id.isin(pre_elg)), f'pre_{i}'] = True \n",
    "    ifa.loc[(ifa.eom >= post_start) & (ifa.eom <= post_end) & (ifa.member_id.isin(post_elg)), f'post_{i}'] = True \n",
    "\n",
    "    ifa.loc[(ifa.eom >= pre_start) & (ifa.eom <= post_end) & (ifa.member_id.isin(pre_post_elg_mems)), f'pre_post_elg_{i}'] = True "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "periods_df = pd.DataFrame(periods, columns=['period', 'pre_start', 'pre_end', 'post_start', 'post_end'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "months_df = pd.DataFrame(months, columns=['eom'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ifa.is_cb_eligible = ifa.is_cb_eligible.fillna(False)\n",
    "ifa.is_unaligned = ifa.is_unaligned.fillna(False)\n",
    "ifa = ifa.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ifa = ifa.assign(is_male=np.where(ifa.gender=='m',1,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assign state\n",
    "ifa = ifa.assign(state=ifa.mco_name.str.split(' ').apply(lambda x: x[1]).replace({'Centene': 'IA'}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ifa.to_parquet('./data/member_periods_v4.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ifa.to_csv('./data/member_periods.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build features + targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "member_periods = pd.read_parquet('./data/member_periods_v4.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ifa' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-f8a556b20fe9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtarget_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'ip_tc'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'er_tc'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'snf_tc'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'amb_tc'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m##\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtc_feats\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mc\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mifa\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;34m'_tc'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mddos_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'ip_ddos'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'er_ddos'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'out_ddos'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'snf_ddos'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'icf_ddos'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'hh_ddos'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'amb_ddos'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'hsp_ddos'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'pro_ddos'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'spc_fac_ddos'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'dme_ddos'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'cls_ddos'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'hha_ddos'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mtop_level_feats\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'age'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'is_male'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'state'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'ggroup'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'line_of_business_id'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'ifa' is not defined"
     ]
    }
   ],
   "source": [
    "target_cols = ['ip_tc', 'er_tc', 'snf_tc', 'amb_tc']\n",
    "##\n",
    "tc_feats = [c for c in ifa.columns if '_tc' in c]\n",
    "ddos_cols = ['ip_ddos', 'er_ddos', 'out_ddos', 'snf_ddos', 'icf_ddos', 'hh_ddos', 'amb_ddos', 'hsp_ddos', 'pro_ddos', 'spc_fac_ddos', 'dme_ddos', 'cls_ddos', 'hha_ddos']\n",
    "top_level_feats = ['age', 'is_male', 'state', 'ggroup', 'line_of_business_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tc_dx_feats = [\n",
    " # 'rx_tc',\n",
    " # 'other_tc',\n",
    " # 'ip_tc',\n",
    " # 'er_tc',\n",
    " # 'out_tc',\n",
    " # 'snf_tc',\n",
    " # 'icf_tc',\n",
    " # 'hh_tc',\n",
    " # 'amb_tc',\n",
    " # 'hsp_tc',\n",
    " # 'pro_tc',\n",
    " # 'spc_fac_tc',\n",
    " # 'dme_tc',\n",
    " # 'cls_tc',\n",
    " # 'hha_tc',\n",
    " 'hcbs_attdpcs_tc',\n",
    " 'hcbs_other_tc',\n",
    " 'hcbs_support_house_tc',\n",
    " 'hcbs_adult_day_tc',\n",
    " 'hcbs_pers_tc',\n",
    " 'hcbs_assist_tech_tc',\n",
    " 'oxygen_tc',\n",
    " 'hosp_bed_tc',\n",
    " 'chf_tc',\n",
    " 'heart_tc',\n",
    " 'copd_tc',\n",
    " 'pulmonar_tc',\n",
    " 'cancer_tc',\n",
    " 'ckd_tc',\n",
    " 'esrd_tc',\n",
    " 'lipidy_tc',\n",
    " 'diab_tc',\n",
    " 'alzh_tc',\n",
    " 'demented_tc',\n",
    " 'stroke_tc',\n",
    " 'hyper_tc',\n",
    " 'fall_tc',\n",
    " 'trans_tc',\n",
    " 'liver_tc',\n",
    " 'hippy_tc',\n",
    " 'depressed_tc',\n",
    " 'psycho_tc',\n",
    " 'druggy_tc',\n",
    " 'boozy_tc',\n",
    " 'paralyzed_tc',\n",
    " 'mono_tc',\n",
    " 'mono_dom_tc',\n",
    " 'hemi_tc',\n",
    " 'hemi_dom_tc',\n",
    " 'para_tc',\n",
    " 'quad_tc',\n",
    " 'tbi_tc',\n",
    " 'obese_tc',\n",
    " 'pressure_ulcer_tc',\n",
    " 'hemophilia_tc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def build_member_features(mdf): \n",
    "mcos = member_periods.mco_name.unique().tolist()\n",
    "mco_cols = [f'is_{m.lower().replace(\" \", \"_\")}' for m in mcos]\n",
    "n_mcos = len(mcos)\n",
    "def encode_mco(mco_str):\n",
    "    one_hot = np.zeros(n_mcos, dtype=int)\n",
    "    one_hot[mcos.index(mco_str)] = 1 \n",
    "    return one_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lobs = member_periods.line_of_business_id.unique().tolist()\n",
    "lob_cols = [f'is_lob_{l}' for l in lobs]\n",
    "n_lobs = len(lobs)\n",
    "def encode_lob(lob):\n",
    "    one_hot = np.zeros(n_lobs, dtype=int)\n",
    "    one_hot[lobs.index(lob)] = 1 \n",
    "    return one_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "groups = member_periods.ggroup.unique().tolist()\n",
    "group_cols = [f'is_group_{l}' for l in groups]\n",
    "n_groups = len(groups)\n",
    "def encode_group(group):\n",
    "    one_hot = np.zeros(n_groups, dtype=int)\n",
    "    one_hot[groups.index(group)] = 1 \n",
    "    return one_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "states = member_periods.state.unique().tolist()\n",
    "state_cols = [f'is_state_{l}' for l in states]\n",
    "n_states = len(states)\n",
    "def encode_state(state):\n",
    "    one_hot = np.zeros(n_states, dtype=int)\n",
    "    one_hot[states.index(state)] = 1 \n",
    "    return one_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wide_ddos_cols = [f'{c}_{i}' for i in range(pre_months) for c in ddos_cols]\n",
    "wide_tc_dx_cols = [f'{c}_{i}' for i in range(pre_months) for c in tc_dx_feats]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_member_features(mdf, months_range):\n",
    "# mdf = member_periods.loc[(member_periods.pre_0) & (member_periods.pre_full_0) & (member_periods.member_id == 102)].sort_values('eom')\n",
    "    # print(months_range)\n",
    "\n",
    "    if len(mdf) == 0:\n",
    "        return mdf\n",
    "        \n",
    "    demographic_data = mdf[top_level_feats + ['member_id']].iloc[-1]\n",
    "    \n",
    "    mdf = months_range.merge(mdf, on='eom', how='left')\n",
    "    mdf = mdf.sort_values('eom')[ddos_cols + tc_dx_feats]\n",
    "    mdf = mdf.fillna(0)\n",
    "    \n",
    "    ddos_data = mdf.to_numpy().reshape([1, -1])\n",
    "\n",
    "    state_data = encode_state(demographic_data.state)\n",
    "    lob_data = encode_lob(demographic_data.line_of_business_id)\n",
    "    group_data = encode_group(demographic_data.ggroup)\n",
    "    data = np.concatenate((ddos_data[0], state_data, lob_data, group_data, np.array([demographic_data.is_male, demographic_data.age, demographic_data.member_id])), axis=0, dtype=float)\n",
    "    cols = wide_ddos_cols + wide_tc_dx_cols + state_cols + lob_cols + group_cols + ['is_male', 'age', 'member_id']\n",
    "\n",
    "    return pd.DataFrame([data], columns=cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mdf = member_periods.loc[(member_periods.pre_0) & (member_periods.pre_full_0 == False) & (member_periods.member_id == 26)].sort_values('eom')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_member_targets(mdf):\n",
    "    if len(mdf) == 0:\n",
    "        return pd.DataFrame([], columns=['member_id', 'target'])\n",
    "    tc = mdf[target_cols].sum().sum()\n",
    "#     pmpm = tc / mdf.cpmm.sum()\n",
    "    return pd.DataFrame([[mdf.iloc[0].member_id, tc]], columns=['member_id', 'target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_targets(post_df):\n",
    "    return post_df.groupby('member_id', as_index=False).apply(build_member_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_features(pre_df, months_range):\n",
    "    return pre_df.groupby('member_id', as_index=False).apply(lambda x: build_member_features(x, months_range))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# build features and targets for each period\n",
    "period_dfs = []\n",
    "for i in tqdm(range(last_valid_pre_start)):\n",
    "    elg = member_periods.loc[member_periods[f'pre_post_elg_{i}']] \n",
    "    pre = elg.loc[elg[f'pre_{i}']] \n",
    "\n",
    "    post = elg.loc[elg[f'post_{i}']] \n",
    "    x = build_features(pre, months_df.loc[i:i+11])\n",
    "    # if i < 42:\n",
    "    y = build_targets(post)\n",
    "    final = x.merge(y, how='left', left_on='member_id', right_on='member_id').assign(period=i)\n",
    "    # else:\n",
    "        # final = x.assign(period=i)\n",
    "    period_dfs.append(final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "master_df = pd.concat(period_dfs)\n",
    "master_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# master_df.to_parquet('./data/master_df.parquet')\n",
    "# master_df.to_parquet('./data/master_ddos_df.parquet')\n",
    "master_df.to_parquet('./data/master_wide_df_v4.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train/Val/Test split\n",
    "Avoid any leakage by doing the splits at the member level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "role = sagemaker.get_execution_role()\n",
    "bucket_name = 'cb-analytics-us-east-2-prd'\n",
    "prefix = 'sagemaker/'\n",
    "file_name = 'master_wide_df_v4.parquet'\n",
    "# my_region = boto3.session.Session().region_name # set the region of the instance\n",
    "\n",
    "obj = boto3.Session().resource('s3').Bucket(bucket_name).Object(os.path.join(prefix, file_name)).get()\n",
    "master_df = pd.read_parquet(io.BytesIO(obj['Body'].read()))\n",
    "master_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# master_df = pd.read_parquet('./data/master_df.parquet')\n",
    "# master_df = pd.read_parquet('./data/master_ddos_df.parquet')\n",
    "master_df = pd.read_parquet('./data/master_wide_df_v4.parquet')\n",
    "# master_df = master_df.loc[master_df.period > 24]\n",
    "# make dtype str for these categorical features\n",
    "# master_df.ggroup = master_df.ggroup.astype(str)\n",
    "# master_df.line_of_business_id = master_df.line_of_business_id.astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'master_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-2872bfc9051c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmaster_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'master_df' is not defined"
     ]
    }
   ],
   "source": [
    "master_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One hot enc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cat_feats = ['gender', 'mco_name', 'ggroup', 'line_of_business_id']\n",
    "# one_hots = pd.get_dummies(master_df[cat_feats])\n",
    "# master_df = pd.concat([master_df, one_hots], axis=1).drop(columns=cat_feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "member_ids = master_df.member_id.unique()\n",
    "n_members = len(member_ids)\n",
    "n_members"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_n = int(n_members * .7)\n",
    "val_n = int(n_members * .15)\n",
    "test_n = n_members - train_n - val_n\n",
    "train_n, val_n, test_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.shuffle(member_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_mems, val_mems, test_mems = np.split(member_ids, [train_n, train_n + val_n])\n",
    "assert train_mems.shape[0] == train_n\n",
    "assert val_mems.shape[0] == val_n\n",
    "assert test_mems.shape[0] == test_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_df = master_df.loc[master_df.member_id.isin(train_mems)]\n",
    "val_df = master_df.loc[master_df.member_id.isin(val_mems)]\n",
    "test_df = master_df.loc[master_df.member_id.isin(test_mems)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalize/encode features if needed\n",
    "not needed for trees, most linear models will do it for you if you pass the param"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_cols = [c for c in training_df.columns if c not in ['member_id', 'target', 'period']]\n",
    "# x_cols = [c for c in training_df.columns if c not in ['member_id', 'target', 'period'] + cat_feats]\n",
    "x = training_df[x_cols]\n",
    "y = training_df.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge = Ridge(alpha=1, normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge.fit(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge.score(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_x = val_df[x_cols]\n",
    "val_y = val_df.target\n",
    "ridge.score(val_x,val_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "histr = HistGradientBoostingRegressor()\n",
    "histr.fit(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "histr.score(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "histr.score(val_x, val_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_preds = histr.predict(x)\n",
    "val_preds = histr.predict(val_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_w_preds = training_df.assign(pred=train_preds, sample='train').merge(periods_df, on='period')\n",
    "val_w_preds = val_df.assign(pred=val_preds, sample='validation').merge(periods_df, on='period')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_cols = ['member_id', 'sample', 'target', 'pred', 'period', 'pre_start', 'pre_end', 'post_start', 'post_end']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat([train_w_preds[out_cols], val_w_preds[out_cols]]).to_csv('hgbr_12_mom_ddos.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted(zip(ridge.coef_, x.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.inspection import permutation_importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = permutation_importance(histr, val_x, val_y, n_repeats=10,random_state=0, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted(zip(result.importances_mean, val_x.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
